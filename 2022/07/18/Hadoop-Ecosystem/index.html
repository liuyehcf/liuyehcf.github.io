<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="阅读更多">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop-Ecosystem">
<meta property="og:url" content="http://example.com/2022/07/18/Hadoop-Ecosystem/index.html">
<meta property="og:site_name" content="Liuye Notebook">
<meta property="og:description" content="阅读更多">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/Hadoop-Ecosystem/HADOOP-ECOSYSTEM-Edureka.png">
<meta property="og:image" content="http://example.com/images/Hadoop-Ecosystem/HadoopEcosystem-min.png">
<meta property="og:image" content="http://example.com/images/Hadoop-Ecosystem/hdfsarchitecture.gif">
<meta property="og:image" content="http://example.com/images/Hadoop-Ecosystem/spark-cluster-overview.png">
<meta property="og:image" content="http://example.com/images/Hadoop-Ecosystem/hive_core_architecture.jpeg">
<meta property="article:published_time" content="2022-07-18T11:17:45.000Z">
<meta property="article:modified_time" content="2025-02-27T15:48:33.000Z">
<meta property="article:author" content="Liuyehcf">
<meta property="article:tag" content="原创">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/Hadoop-Ecosystem/HADOOP-ECOSYSTEM-Edureka.png">

<link rel="canonical" href="http://example.com/2022/07/18/Hadoop-Ecosystem/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hadoop-Ecosystem | Liuye Notebook</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Liuye Notebook</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-explore">

    <a href="/explore/" rel="section"><i class="fa fa-sitemap fa-fw"></i>发现</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/07/18/Hadoop-Ecosystem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Liuyehcf">
      <meta itemprop="description" content="大音希声，大象无形">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liuye Notebook">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop-Ecosystem
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-07-18 19:17:45" itemprop="dateCreated datePublished" datetime="2022-07-18T19:17:45+08:00">2022-07-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-02-27 23:48:33" itemprop="dateModified" datetime="2025-02-27T23:48:33+08:00">2025-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Database/" itemprop="url" rel="index"><span itemprop="name">Database</span></a>
                </span>
            </span>

          
            <span id="/2022/07/18/Hadoop-Ecosystem/" class="post-meta-item leancloud_visitors" data-flag-title="Hadoop-Ecosystem" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/07/18/Hadoop-Ecosystem/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/07/18/Hadoop-Ecosystem/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>阅读更多</strong></p>
<span id="more"></span>
<h1 id="1-overview"><a class="markdownIt-Anchor" href="#1-overview"></a> 1 Overview</h1>
<p>Below are the Hadoop components, that together form a Hadoop ecosystem:</p>
<ul>
<li><code>HDFS</code> -&gt; Hadoop Distributed File System</li>
<li><code>YARN</code> -&gt; Yet Another Resource Negotiator</li>
<li><code>MapReduce</code> -&gt; Data processing using programming</li>
<li><code>Spark</code> -&gt; In-memory Data Processing</li>
<li><code>PIG</code> -&gt; Data Processing Services using Query (SQL-like)</li>
<li><code>HBase</code> -&gt; NoSQL Database</li>
<li><code>Mahout &amp; Spark MLlib</code> -&gt; Machine Learning</li>
<li><code>Drill</code> -&gt; SQL on Hadoop</li>
<li><code>Zookeeper</code> -&gt; Managing Cluster</li>
<li><code>Oozie</code> -&gt; Job Scheduling</li>
<li><code>Flume</code> -&gt; Data Ingesting Services</li>
<li><code>Solr &amp; Lucene</code> -&gt; Searching &amp; Indexing</li>
<li><code>Ambari</code> -&gt; Provision, Monitor and Maintain cluster</li>
</ul>
<p><img src="/images/Hadoop-Ecosystem/HADOOP-ECOSYSTEM-Edureka.png" alt="HADOOP-ECOSYSTEM-Edureka" /></p>
<p><img src="/images/Hadoop-Ecosystem/HadoopEcosystem-min.png" alt="HadoopEcosystem-min" /></p>
<h1 id="2-hdfs"><a class="markdownIt-Anchor" href="#2-hdfs"></a> 2 HDFS</h1>
<blockquote>
<p>HDFS has a master/slave architecture. An HDFS cluster consists of a single NameNode, a master server that manages the file system namespace and regulates access to files by clients. In addition, there are a number of DataNodes, usually one per node in the cluster, which manage storage attached to the nodes that they run on. HDFS exposes a file system namespace and allows user data to be stored in files. Internally, a file is split into one or more blocks and these blocks are stored in a set of DataNodes. The NameNode executes file system namespace operations like opening, closing, and renaming files and directories. It also determines the mapping of blocks to DataNodes. The DataNodes are responsible for serving read and write requests from the file system’s clients. The DataNodes also perform block creation, deletion, and replication upon instruction from the NameNode.</p>
</blockquote>
<p><img src="/images/Hadoop-Ecosystem/hdfsarchitecture.gif" alt="hdfsarchitecture" /></p>
<h2 id="21-deployment-via-docker"><a class="markdownIt-Anchor" href="#21-deployment-via-docker"></a> 2.1 Deployment via Docker</h2>
<p><strong>Import paths of docker:</strong></p>
<ul>
<li><code>/var/log/hadoop</code>
<ul>
<li><code>/var/log/hadoop/hadoop-hadoop-namenode-$(hostname).out</code></li>
<li><code>/var/log/hadoop/hadoop-hadoop-datanode-$(hostname).out</code></li>
<li><code>/var/log/hadoop/hadoop-hadoop-resourcemanager-$(hostname).out</code></li>
<li><code>/var/log/hadoop/hadoop-hadoop-nodemanager-$(hostname).out</code></li>
<li><code>userlogs</code>: Logs for applications that are submitted to yarn.</li>
</ul>
</li>
</ul>
<p><strong>Important ports:</strong></p>
<ul>
<li><code>8020</code>: The NameNode’s default RPC port is 8020.</li>
<li><code>9866</code>: The datanode server address and port for data transfer.</li>
<li><code>8042</code>: NodeManager (Web UI).</li>
<li><code>8088</code>: ResourceManager (Web UI).</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=hadoop-ns</span><br><span class="line">HADOOP_CONTAINER_NAME=hadoop</span><br><span class="line"></span><br><span class="line">docker run -dit --name <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> --hostname <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> --privileged -p 8020:8020 -p 9866:9866 -p 8042:8042 -p 8088:8088 apache/hadoop:3.3.6 bash</span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/core-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;hdfs://<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:8020&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/hdfs-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.replication&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;1&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/hadoop/data&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:9866&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.http.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:9864&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:9867&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.hostname&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/yarn-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;8192&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;4&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;1024&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;8192&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/mapred-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;yarn&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/hadoop/share/hadoop/mapreduce/*,/opt/hadoop/share/hadoop/mapreduce/lib/*&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Format</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs namenode -format&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;mkdir -p /opt/hadoop/data&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Retart all daemons</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs --daemon stop namenode; hdfs --daemon start namenode&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs --daemon stop datanode; hdfs --daemon start datanode&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;yarn --daemon stop resourcemanager; yarn --daemon start resourcemanager&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;yarn --daemon stop nodemanager; yarn --daemon start nodemanager&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;mapred --daemon stop historyserver; mapred --daemon start historyserver&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Report status</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs dfsadmin -report&#x27;</span></span><br></pre></td></tr></table></figure>
<p>Test:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar pi 10 100&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="22-deployment-via-docker-and-kerberos"><a class="markdownIt-Anchor" href="#22-deployment-via-docker-and-kerberos"></a> 2.2 Deployment via Docker and Kerberos</h2>
<h3 id="221-kerberos-basics"><a class="markdownIt-Anchor" href="#221-kerberos-basics"></a> 2.2.1 Kerberos Basics</h3>
<p><strong>Concepts:</strong></p>
<ul>
<li>Key Distribution Center, KDC
<ul>
<li>The central server responsible for managing authentication.</li>
<li>Comprises two sub-components:
<ul>
<li>Authentication Server (AS): Authenticates the client and issues the Ticket Granting Ticket (TGT).</li>
<li>Ticket Granting Server (TGS): Issues service-specific tickets upon request.</li>
</ul>
</li>
</ul>
</li>
<li>Principal: A unique identity (user, service, or host) in the Kerberos system, e.g., <code>user@REALM</code> or <code>service/hostname@REALM</code>.</li>
<li>Realm: A logical network served by a single KDC, identified by an uppercase string, e.g., <code>EXAMPLE.COM</code>.</li>
<li>Keytab: A file storing pre-shared credentials for a user or service, used for automated authentication.</li>
<li>Ticket: A temporary set of credentials that allows a principal to authenticate to services.
<ul>
<li>Ticket Granting Ticket (TGT): Issued by the AS, used to request service tickets.</li>
<li>Service Ticket: Allows access to a specific service.</li>
</ul>
</li>
</ul>
<p><strong>Kerberos Commands:</strong></p>
<ul>
<li><code>kinit &lt;principal&gt;[@&lt;kerberos_realm&gt;]</code>: Login with password.</li>
<li><code>kinit -kt &lt;keytabpath&gt; &lt;principal&gt;[@&lt;kerberos_realm&gt;]</code>: Login with keytab.</li>
<li><code>kinit -c &lt;cache_path&gt; &lt;principal&gt;[@&lt;kerberos_realm&gt;]</code>: Specific cache path.</li>
<li><code>klist</code></li>
<li><code>klist -c &lt;cache_path&gt;</code></li>
<li><code>kdestroy</code></li>
<li><code>kdestroy -c &lt;cache_path&gt;</code></li>
<li>Environments:
<ul>
<li><code>export KRB5_TRACE=/dev/stdout</code></li>
<li><code>export KRB5_CONFIG=&lt;path/to/krb5.conf&gt;</code></li>
<li><code>export KRB5CCNAME=FILE:/tmp/krb5cc_testuser</code>: Use local file as cache.</li>
<li><code>export KRB5CCNAME=MEMORY:</code>: Use meory as cache.</li>
</ul>
</li>
</ul>
<p><strong><code>kadmin.local</code> Commands:</strong></p>
<ul>
<li><code>?</code>: help doc.</li>
</ul>
<p><strong>Tips:</strong></p>
<ul>
<li>Make sure target user has permission to read related files, including config, TGT, keyTab etc.</li>
</ul>
<h3 id="222-kerberos-container"><a class="markdownIt-Anchor" href="#222-kerberos-container"></a> 2.2.2 Kerberos Container</h3>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=hadoop-ns</span><br><span class="line">HADOOP_CONTAINER_NAME=hadoop-with-kerberos</span><br><span class="line">KERBEROS_CONTAINER_NAME=kerberos</span><br><span class="line">REAL_DOMAIN=liuyehcf.org</span><br><span class="line">HADOOP_HOSTNAME=<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>.<span class="variable">$&#123;REAL_DOMAIN&#125;</span></span><br><span class="line">KERBEROS_HOSTNAME=<span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span>.<span class="variable">$&#123;REAL_DOMAIN&#125;</span></span><br><span class="line">KERBEROS_LOGIC_DOMAIN=example.com</span><br><span class="line">KERBEROS_LOGIC_DOMAIN_UPPER=$(<span class="built_in">echo</span> <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN&#125;</span> | <span class="built_in">tr</span> <span class="string">&quot;[:lower:]&quot;</span> <span class="string">&quot;[:upper:]&quot;</span>)</span><br><span class="line"></span><br><span class="line">docker run -dit --name <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> --hostname <span class="variable">$&#123;KERBEROS_HOSTNAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> --privileged -p 88:88 -p 464:464 -p 749:749 ubuntu:xenial</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install kerberos</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;apt update&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;DEBIAN_FRONTEND=noninteractive apt install -y ntp python-dev python-pip python-wheel python-setuptools python-pkg-resources krb5-admin-server krb5-kdc&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;apt install -y vim iputils-ping iproute2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup kerberos config</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;tee /etc/krb5.conf &gt; /dev/null &lt;&lt; EOF</span></span><br><span class="line"><span class="string">[libdefaults]</span></span><br><span class="line"><span class="string">    default_realm = <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">    dns_lookup_realm = false</span></span><br><span class="line"><span class="string">    dns_lookup_kdc = false</span></span><br><span class="line"><span class="string">    ticket_lifetime = 24h</span></span><br><span class="line"><span class="string">    renew_lifetime = 7d</span></span><br><span class="line"><span class="string">    forwardable = true</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string">    <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span> = &#123;</span></span><br><span class="line"><span class="string">        kdc = <span class="variable">$&#123;KERBEROS_HOSTNAME&#125;</span></span></span><br><span class="line"><span class="string">        admin_server = <span class="variable">$&#123;KERBEROS_HOSTNAME&#125;</span></span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[domain_realm]</span></span><br><span class="line"><span class="string">    <span class="variable">$&#123;REAL_DOMAIN&#125;</span> = <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">    .<span class="variable">$&#123;REAL_DOMAIN&#125;</span> = <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /etc/krb5kdc/kdc.conf &lt;&lt; EOF</span></span><br><span class="line"><span class="string">[kdcdefaults]</span></span><br><span class="line"><span class="string">    kdc_ports = 88</span></span><br><span class="line"><span class="string">    kdc_tcp_ports = 88</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string">    <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span> = &#123;</span></span><br><span class="line"><span class="string">        database_name = /var/lib/krb5kdc/principal</span></span><br><span class="line"><span class="string">        admin_keytab = /etc/krb5kdc/kadm5.keytab</span></span><br><span class="line"><span class="string">        acl_file = /etc/krb5kdc/kadm5.acl</span></span><br><span class="line"><span class="string">        key_stash_file = /etc/krb5kdc/stash</span></span><br><span class="line"><span class="string">        log_file = /var/log/krb5kdc.log</span></span><br><span class="line"><span class="string">        kdc_ports = 88</span></span><br><span class="line"><span class="string">        max_life = 10h 0m 0s</span></span><br><span class="line"><span class="string">        max_renewable_life = 7d 0h 0m 0s</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /etc/krb5kdc/kadm5.acl &lt;&lt; EOF</span></span><br><span class="line"><span class="string">*/admin@<span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span> *</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;kdb5_util create -s &lt;&lt;EOF</span></span><br><span class="line"><span class="string">!Abcd1234</span></span><br><span class="line"><span class="string">!Abcd1234</span></span><br><span class="line"><span class="string">EOF&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;/usr/sbin/krb5kdc&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;/usr/sbin/kadmind&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create principal for hadoop</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;mkdir -p /etc/security/keytabs&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;kadmin.local &lt;&lt;EOF</span></span><br><span class="line"><span class="string">addprinc -randkey nn/<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>@<span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">addprinc -randkey dn/<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>@<span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">listprincs</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ktadd -k /etc/security/keytabs/nn.service.keytab nn/<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>@<span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">ktadd -k /etc/security/keytabs/dn.service.keytab dn/<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>@<span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">quit</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create principal for user</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;kadmin.local &lt;&lt;EOF</span></span><br><span class="line"><span class="string">addprinc -pw 123456 testuser</span></span><br><span class="line"><span class="string">listprincs</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">quit</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br></pre></td></tr></table></figure>
<p><strong>Test:</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># password: 123456</span></span><br><span class="line">kinit testuser</span><br><span class="line">klist</span><br></pre></td></tr></table></figure>
<h3 id="223-hadoop-container"><a class="markdownIt-Anchor" href="#223-hadoop-container"></a> 2.2.3 Hadoop Container</h3>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=hadoop-ns</span><br><span class="line">HADOOP_CONTAINER_NAME=hadoop-with-kerberos</span><br><span class="line">KERBEROS_CONTAINER_NAME=kerberos</span><br><span class="line">REAL_DOMAIN=liuyehcf.org</span><br><span class="line">HADOOP_HOSTNAME=<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>.<span class="variable">$&#123;REAL_DOMAIN&#125;</span></span><br><span class="line">KERBEROS_HOSTNAME=<span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span>.<span class="variable">$&#123;REAL_DOMAIN&#125;</span></span><br><span class="line">KERBEROS_LOGIC_DOMAIN=example.com</span><br><span class="line">KERBEROS_LOGIC_DOMAIN_UPPER=$(<span class="built_in">echo</span> <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN&#125;</span> | <span class="built_in">tr</span> <span class="string">&quot;[:lower:]&quot;</span> <span class="string">&quot;[:upper:]&quot;</span>)</span><br><span class="line"></span><br><span class="line">docker run -dit --name <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> --hostname <span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> --privileged -p 8020:8020 -p 9866:9866 apache/hadoop:3.3.6 bash</span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/core-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;hdfs://<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>:8020&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">      &lt;name&gt;hadoop.security.authentication&lt;/name&gt;</span></span><br><span class="line"><span class="string">      &lt;value&gt;kerberos&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">      &lt;name&gt;hadoop.security.authorization&lt;/name&gt;</span></span><br><span class="line"><span class="string">      &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/hdfs-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.replication&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;1&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/hadoop/data&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>:9866&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.http.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>:9864&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>:9867&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.hostname&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;<span class="variable">$&#123;HADOOP_HOSTNAME&#125;</span>&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;nn/_HOST@<span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span>&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/etc/security/keytabs/nn.service.keytab&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;dn/_HOST@<span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span>&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/etc/security/keytabs/dn.service.keytab&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.block.access.token.master.key.num&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;2&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.block.access.token.lifetime&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;600&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup kerberos config</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;sudo tee /etc/krb5.conf &gt; /dev/null &lt;&lt; EOF</span></span><br><span class="line"><span class="string">[libdefaults]</span></span><br><span class="line"><span class="string">    default_realm = <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">    dns_lookup_realm = false</span></span><br><span class="line"><span class="string">    dns_lookup_kdc = false</span></span><br><span class="line"><span class="string">    ticket_lifetime = 24h</span></span><br><span class="line"><span class="string">    renew_lifetime = 7d</span></span><br><span class="line"><span class="string">    forwardable = true</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string">    <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span> = &#123;</span></span><br><span class="line"><span class="string">        kdc = <span class="variable">$&#123;KERBEROS_HOSTNAME&#125;</span></span></span><br><span class="line"><span class="string">        admin_server = <span class="variable">$&#123;KERBEROS_HOSTNAME&#125;</span></span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[domain_realm]</span></span><br><span class="line"><span class="string">    <span class="variable">$&#123;REAL_DOMAIN&#125;</span> = <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">    .<span class="variable">$&#123;REAL_DOMAIN&#125;</span> = <span class="variable">$&#123;KERBEROS_LOGIC_DOMAIN_UPPER&#125;</span></span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy keytab</span></span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span>:/etc/security/keytabs/nn.service.keytab /tmp/nn.service.keytab</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;KERBEROS_CONTAINER_NAME&#125;</span>:/etc/security/keytabs/dn.service.keytab /tmp/dn.service.keytab</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/nn.service.keytab <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/etc/security/keytabs/nn.service.keytab</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/dn.service.keytab <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/etc/security/keytabs/dn.service.keytab</span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;sudo chmod 644 /etc/security/keytabs/nn.service.keytab&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;sudo chmod 644 /etc/security/keytabs/dn.service.keytab&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install jsvc</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;sudo mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo_bak&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;sudo yum install -y jsvc&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Format</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs namenode -format&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;sudo mkdir -p /opt/hadoop/data&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Retart all daemons</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs --daemon stop namenode; hdfs --daemon start namenode&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;HDFS_DATANODE_SECURE_USER=root; \</span></span><br><span class="line"><span class="string">        JSVC_HOME=/bin; \</span></span><br><span class="line"><span class="string">        JAVA_HOME=/usr/lib/jvm/jre; \</span></span><br><span class="line"><span class="string">        sudo -E /opt/hadoop/bin/hdfs --daemon stop datanode; \</span></span><br><span class="line"><span class="string">        sudo -E /opt/hadoop/bin/hdfs --daemon start datanode&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Report status</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;kinit testuser &lt;&lt;EOF</span></span><br><span class="line"><span class="string">123456</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs dfsadmin -report&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>Key points:</strong></p>
<ul>
<li>Directory <code>/opt/hadoop/data</code> must can be accessed by the user started datanode.</li>
<li>Credential file <code>/etc/security/keytabs/dn.service.keytab</code> must can be accessed by the user started datanode.</li>
<li>If <code>ignore.secure.ports.for.testing</code> is set to <code>false</code>, then the http port and tcp port must be smaller than 1023, otherwise it cannot pass the check.</li>
</ul>
<h2 id="23-configuration"><a class="markdownIt-Anchor" href="#23-configuration"></a> 2.3 Configuration</h2>
<ol>
<li><code>core-site.xml</code>
<ul>
<li>Path: <code>$HADOOP_HOME/etc/hadoop/core-site.xml</code></li>
<li>Description: Contains configuration settings for Hadoop’s core system, including the default filesystem URI.</li>
<li><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.3.6/hadoop-project-dist/hadoop-common/core-default.xml">core-default.xml</a></li>
</ul>
</li>
<li><code>hdfs-site.xml</code>
<ul>
<li>Path: <code>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</code></li>
<li>Description: Contains configuration settings specific to HDFS.</li>
<li><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.3.6/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a></li>
</ul>
</li>
<li><code>yarn-site.xml</code>
<ul>
<li>Path: <code>$HADOOP_HOME/etc/hadoop/yarn-site.xml</code></li>
<li>Description: Contains configuration settings for YARN (Yet Another Resource Negotiator).</li>
<li><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.3.6/hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a></li>
</ul>
</li>
<li><code>mapred-site.xml</code>
<ul>
<li>Path: <code>$HADOOP_HOME/etc/hadoop/mapred-site.xml</code></li>
<li>Description: Contains configuration settings specific to MapReduce.</li>
<li><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.3.6/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default.xml</a></li>
</ul>
</li>
<li><code>hadoop-env.sh</code>
<ul>
<li>Path: <code>$HADOOP_HOME/etc/hadoop/hadoop-env.sh</code></li>
<li>Description: Sets environment variables for Hadoop processes, such as JAVA_HOME.</li>
</ul>
</li>
<li><code>yarn-env.sh</code>
<ul>
<li>Path: <code>$HADOOP_HOME/etc/hadoop/yarn-env.sh</code></li>
<li>Description: Sets environment variables for YARN.</li>
</ul>
</li>
<li><code>log4j.properties</code>
<ul>
<li>Path: <code>$HADOOP_HOME/etc/hadoop/log4j.properties</code></li>
<li>Description: Configures logging for Hadoop.</li>
</ul>
</li>
</ol>
<h3 id="231-how-to-config-dfsnameservices"><a class="markdownIt-Anchor" href="#231-how-to-config-dfsnameservices"></a> 2.3.1 How to config dfs.nameservices</h3>
<p><strong><code>core-site.xml</code></strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong><code>hdfs-site.xml</code></strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>p0,p1,p2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.p0<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>192.168.0.1:12000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.p1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>192.168.0.2:12000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.p2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>192.168.0.3:12000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="232-support-config-hot-loading"><a class="markdownIt-Anchor" href="#232-support-config-hot-loading"></a> 2.3.2 Support config hot loading</h3>
<p><code>FileSystem::CACHE</code> will cache filesystem object, cache key is built from <code>uri</code> and <code>Configuration</code>, if you only modify <code>hdfs-site.xml</code> file itself, the object <code>Configuration</code> will be exactly the same, so comes with the cache hit.</p>
<p>How to disable it?, set property <code>fs.&lt;protocol&gt;.impl.disable.cache</code> to <code>true</code> in <code>hdfs-site.xml</code></p>
<ul>
<li>For hdfs, the property name is: <code>fs.hdfs.impl.disable.cache</code></li>
</ul>
<h3 id="233-hedge-read"><a class="markdownIt-Anchor" href="#233-hedge-read"></a> 2.3.3 Hedge read</h3>
<ul>
<li><code>dfs.client.hedged.read.threadpool.size</code></li>
<li><code>dfs.client.hedged.read.threshold.millis</code></li>
</ul>
<h2 id="24-command"><a class="markdownIt-Anchor" href="#24-command"></a> 2.4 Command</h2>
<h3 id="241-daemon"><a class="markdownIt-Anchor" href="#241-daemon"></a> 2.4.1 daemon</h3>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon stop namenode</span><br><span class="line">hdfs --daemon stop datanode</span><br><span class="line">yarn --daemon stop resourcemanager</span><br><span class="line">yarn --daemon stop nodemanager</span><br><span class="line">mapred --daemon stop historyserver</span><br><span class="line"></span><br><span class="line">hdfs --daemon start namenode</span><br><span class="line">hdfs --daemon start datanode</span><br><span class="line">yarn --daemon start resourcemanager</span><br><span class="line">yarn --daemon start nodemanager</span><br><span class="line">mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>
<h3 id="242-hdfs"><a class="markdownIt-Anchor" href="#242-hdfs"></a> 2.4.2 hdfs</h3>
<h4 id="2421-file-path"><a class="markdownIt-Anchor" href="#2421-file-path"></a> 2.4.2.1 File Path</h4>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">ls</span> -R &lt;path&gt;</span><br></pre></td></tr></table></figure>
<h4 id="2422-file-status"><a class="markdownIt-Anchor" href="#2422-file-status"></a> 2.4.2.2 File Status</h4>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs fsck &lt;path&gt;</span><br><span class="line">hdfs fsck &lt;path&gt; -files -blocks -replication</span><br></pre></td></tr></table></figure>
<h4 id="2423-show-content"><a class="markdownIt-Anchor" href="#2423-show-content"></a> 2.4.2.3 Show Content</h4>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For text file</span></span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> &lt;path&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># For avro file</span></span><br><span class="line">hdfs dfs -text &lt;path.avro&gt;</span><br></pre></td></tr></table></figure>
<h4 id="2424-grant-permission"><a class="markdownIt-Anchor" href="#2424-grant-permission"></a> 2.4.2.4 Grant Permission</h4>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -setfacl -R -m user:hive:rwx /</span><br><span class="line">hdfs dfs -setfacl -R -m default:user:hive:rwx /</span><br><span class="line">hdfs dfs -getfacl /</span><br></pre></td></tr></table></figure>
<h3 id="243-yarn"><a class="markdownIt-Anchor" href="#243-yarn"></a> 2.4.3 yarn</h3>
<h4 id="2431-node"><a class="markdownIt-Anchor" href="#2431-node"></a> 2.4.3.1 Node</h4>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yarn node -list</span><br><span class="line">yarn node -list -showDetails</span><br></pre></td></tr></table></figure>
<h4 id="2432-application"><a class="markdownIt-Anchor" href="#2432-application"></a> 2.4.3.2 Application</h4>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yarn application -list</span><br><span class="line">yarn application -list -appStates ALL</span><br><span class="line"></span><br><span class="line">yarn application -status &lt;appid&gt;</span><br><span class="line">yarn logs -applicationId &lt;appid&gt;</span><br><span class="line"></span><br><span class="line">yarn application -<span class="built_in">kill</span> &lt;appid&gt;</span><br></pre></td></tr></table></figure>
<h2 id="25-tips"><a class="markdownIt-Anchor" href="#25-tips"></a> 2.5 Tips</h2>
<h3 id="251-how-to-access-a-hadoop-cluster-started-via-docker"><a class="markdownIt-Anchor" href="#251-how-to-access-a-hadoop-cluster-started-via-docker"></a> 2.5.1 How to access a hadoop cluster started via docker</h3>
<p>For linux, there are two ways of approaching this:</p>
<ol>
<li>Access hadoop via container’s ip.</li>
</ol>
<p>For mac with m chip, the above methods cannot work, because there will be an extra virtualization layer between mac and the container. Here are steps of how we can access hadoop in this situation:</p>
<ul>
<li>We can use hostname to access both namenode and datanode, the hostname must be resolved in both container and Mac, and the container’s name should be the best solution.</li>
</ul>
<ol>
<li>Set port mapping for namenode’s port (<code>8020</code> bydefault) and datanode’s port (<code>9866</code> by default).</li>
<li>Update <code>/etc/hosts</code>, mapping hadoop’s container’s name to <code>127.0.0.1</code>.</li>
<li>Config <code>dfs.datanode.hostname</code> at hadoop side (i.e. Container side), set its value to container’s name.</li>
<li>Config <code>dfs.client.use.datanode.hostname</code> to <code>true</code> at the client side (i.e. Mac side), otherwise it will use container’s ip address, which is unconnected between mac and container because of the extra virtualization layer.</li>
<li>Access hadoop via container’s name.</li>
</ol>
<h3 id="252-sdk-dont-recognize-hadoop_conf_dir-automatically"><a class="markdownIt-Anchor" href="#252-sdk-dont-recognize-hadoop_conf_dir-automatically"></a> 2.5.2 SDK don’t recognize HADOOP_CONF_DIR automatically</h3>
<p>You need to implement the parsing of the path yourself.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">hadoopConf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">String</span> <span class="variable">hadoopConfDir</span> <span class="operator">=</span> System.getenv(HADOOP_CONF_ENV);</span><br><span class="line">    <span class="keyword">if</span> (StringUtils.isNotBlank(hadoopConfDir)) &#123;</span><br><span class="line">        addHadoopConfIfFound(hadoopConf, hadoopConfDir);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">addHadoopConfIfFound</span><span class="params">(Configuration configuration,</span></span><br><span class="line"><span class="params">        String possibleHadoopConfPath)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">new</span> <span class="title class_">File</span>(possibleHadoopConfPath).exists()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">new</span> <span class="title class_">File</span>(possibleHadoopConfPath + <span class="string">&quot;/core-site.xml&quot;</span>).exists()) &#123;</span><br><span class="line">            configuration.addResource(</span><br><span class="line">                    <span class="keyword">new</span> <span class="title class_">org</span>.apache.hadoop.fs.Path(possibleHadoopConfPath + <span class="string">&quot;/core-site.xml&quot;</span>));</span><br><span class="line">            LOGGER.debug(<span class="string">&quot;Adding &#123;&#125;/core-site.xml to hadoop configuration&quot;</span>,</span><br><span class="line">                    possibleHadoopConfPath);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">new</span> <span class="title class_">File</span>(possibleHadoopConfPath + <span class="string">&quot;/hdfs-site.xml&quot;</span>).exists()) &#123;</span><br><span class="line">            configuration.addResource(</span><br><span class="line">                    <span class="keyword">new</span> <span class="title class_">org</span>.apache.hadoop.fs.Path(possibleHadoopConfPath + <span class="string">&quot;/hdfs-site.xml&quot;</span>));</span><br><span class="line">            LOGGER.debug(<span class="string">&quot;Adding &#123;&#125;/hdfs-site.xml to hadoop configuration&quot;</span>,</span><br><span class="line">                    possibleHadoopConfPath);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="3-spark"><a class="markdownIt-Anchor" href="#3-spark"></a> 3 Spark</h1>
<p><a target="_blank" rel="noopener" href="https://www.databricks.com/glossary/what-is-apache-spark">What Is Apache Spark?</a></p>
<p><img src="/images/Hadoop-Ecosystem/spark-cluster-overview.png" alt="spark-cluster-overview" /></p>
<h2 id="31-deployment"><a class="markdownIt-Anchor" href="#31-deployment"></a> 3.1 Deployment</h2>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">ROOT=$(<span class="built_in">dirname</span> <span class="string">&quot;<span class="variable">$0</span>&quot;</span>)</span><br><span class="line">ROOT=$(<span class="built_in">cd</span> <span class="string">&quot;<span class="variable">$ROOT</span>&quot;</span>; <span class="built_in">pwd</span>)</span><br><span class="line"></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz</span><br><span class="line">tar -zxf spark-3.5.1-bin-hadoop3.tgz</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=<span class="variable">$&#123;ROOT&#125;</span>/spark-3.5.1-bin-hadoop3</span><br><span class="line"><span class="built_in">cat</span> &gt; <span class="variable">$&#123;SPARK_HOME&#125;</span>/conf/spark-env.sh &lt;&lt; <span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">SPARK_MASTER_HOST=localhost</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;SPARK_HOME&#125;</span>/sbin/start-master.sh</span><br><span class="line"><span class="variable">$&#123;SPARK_HOME&#125;</span>/sbin/start-worker.sh spark://127.0.0.1:7077</span><br></pre></td></tr></table></figure>
<p><strong>Stop:</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$&#123;SPARK_HOME&#125;</span>/sbin/stop-master.sh</span><br><span class="line"><span class="variable">$&#123;SPARK_HOME&#125;</span>/sbin/stop-worker.sh</span><br></pre></td></tr></table></figure>
<p><strong>Test:</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$&#123;SPARK_HOME&#125;</span>/bin/spark-shell</span><br><span class="line"></span><br><span class="line">scala&gt; val nums = sc.parallelize(1 to 10)</span><br><span class="line">scala&gt; println(nums.count())</span><br><span class="line">scala&gt; :quit</span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;SPARK_HOME&#125;</span>/bin/spark-submit <span class="variable">$&#123;SPARK_HOME&#125;</span>/examples/src/main/python/pi.py 10</span><br></pre></td></tr></table></figure>
<h2 id="32-tips"><a class="markdownIt-Anchor" href="#32-tips"></a> 3.2 Tips</h2>
<h3 id="321-spark-sql"><a class="markdownIt-Anchor" href="#321-spark-sql"></a> 3.2.1 Spark-Sql</h3>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> catalogs;</span><br><span class="line"><span class="keyword">set</span> catalog <span class="operator">&lt;</span>catalog_name<span class="operator">&gt;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> databases;</span><br><span class="line">use <span class="operator">&lt;</span>database_name<span class="operator">&gt;</span>;</span><br></pre></td></tr></table></figure>
<h3 id="322-spark-shell"><a class="markdownIt-Anchor" href="#322-spark-shell"></a> 3.2.2 Spark-Shell</h3>
<h4 id="3221-read-parquetorcavro-file"><a class="markdownIt-Anchor" href="#3221-read-parquetorcavro-file"></a> 3.2.2.1 Read parquet/orc/avro file</h4>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># avro is not built-in format</span></span><br><span class="line">spark-shell --packages org.apache.spark:spark-avro_2.12:3.5.2</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.read.format(<span class="string">&quot;parquet&quot;</span>).load(<span class="string">&quot;hdfs://192.168.64.2/user/iceberg/demo/db/table/data/00000-0-e424d965-50e8-4f61-abc7-6e6c117876f4-0-00001.parquet&quot;</span>).show(<span class="built_in">truncate</span>=<span class="literal">false</span>)</span><br><span class="line">spark.read.format(<span class="string">&quot;avro&quot;</span>).load(<span class="string">&quot;hdfs://192.168.64.2/user/iceberg/demo/demo_namespace/demo_table/metadata/snap-2052751058123365495-1-7a31848a-3e5f-43c7-886a-0a8d5f6c8ed7.avro&quot;</span>).show(<span class="built_in">truncate</span>=<span class="literal">false</span>)</span><br></pre></td></tr></table></figure>
<h1 id="4-hive"><a class="markdownIt-Anchor" href="#4-hive"></a> 4 Hive</h1>
<p><a target="_blank" rel="noopener" href="https://www.databricks.com/glossary/apache-hive">What is Apache Hive?</a></p>
<p><img src="/images/Hadoop-Ecosystem/hive_core_architecture.jpeg" alt="hive_core_architecture" /></p>
<h2 id="41-components"><a class="markdownIt-Anchor" href="#41-components"></a> 4.1 Components</h2>
<h3 id="411-hive-server-2-hs2"><a class="markdownIt-Anchor" href="#411-hive-server-2-hs2"></a> 4.1.1 Hive-Server 2 (HS2)</h3>
<p>HS2 supports multi-client concurrency and authentication. It is designed to provide better support for open API clients like JDBC and ODBC.</p>
<h3 id="412-hive-metastore-server-hms"><a class="markdownIt-Anchor" href="#412-hive-metastore-server-hms"></a> 4.1.2 Hive Metastore Server (HMS)</h3>
<p>The Hive Metastore (HMS) is a central repository of metadata for Hive tables and partitions in a relational database, and provides clients (including Hive, Impala and Spark) access to this information using the metastore service API. It has become a building block for data lakes that utilize the diverse world of open-source software, such as Apache Spark and Presto. In fact, a whole ecosystem of tools, open-source and otherwise, are built around the Hive Metastore, some of which this diagram illustrates.</p>
<h2 id="42-deployment-via-docker"><a class="markdownIt-Anchor" href="#42-deployment-via-docker"></a> 4.2 Deployment via Docker</h2>
<p>Here is a summary of the compatible versions of Apache Hive and Hadoop (refer to <a target="_blank" rel="noopener" href="https://hive.apache.org/general/downloads/">Apache Hive Download</a> for details):</p>
<ul>
<li><code>Hive 4.0.0</code>: Works with <code>Hadoop 3.3.6</code>, <code>Tez 0.10.3</code></li>
</ul>
<p><strong>Issues:</strong></p>
<ul>
<li><strong>When setting <code>IS_RESUME=true</code>, container <code>hiveserver2</code> can restart if it is started via <code>docker run -d</code>. And it cannot restart if it is started via <code>docker create &amp; docker start</code>, still don’t know why.</strong></li>
<li><strong>Don’t use <code>apache-tez-0.10.3-bin.tar.gz</code> directly but use <code>share/tez.tar.gz</code> after uncompressing. (<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/72211046/error-could-not-find-or-load-main-class-org-apache-tez-dag-app-dagappmaster">Error: Could not find or load main class org.apache.tez.dag.app.DAGAppMaster</a>)</strong></li>
</ul>
<h3 id="421-use-built-in-derby"><a class="markdownIt-Anchor" href="#421-use-built-in-derby"></a> 4.2.1 Use built-in Derby</h3>
<p><a target="_blank" rel="noopener" href="https://hive.apache.org/developement/quickstart/">Apache Hive - Quickstart</a></p>
<p>Start a hive container joining the shared network.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=hadoop-ns</span><br><span class="line">HADOOP_CONTAINER_NAME=hadoop</span><br><span class="line">HIVE_PREFIX=hive-with-derby</span><br><span class="line">HIVE_METASTORE_CONTAINER_NAME=<span class="variable">$&#123;HIVE_PREFIX&#125;</span>-metastore</span><br><span class="line">HIVE_SERVER_CONTAINER_NAME=<span class="variable">$&#123;HIVE_PREFIX&#125;</span>-server</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download tez resources and put to hdfs</span></span><br><span class="line"><span class="keyword">if</span> [ ! -e /tmp/apache-tez-0.10.3-bin.tar.gz ]; <span class="keyword">then</span></span><br><span class="line">    wget -O /tmp/apache-tez-0.10.3-bin.tar.gz  https://downloads.apache.org/tez/0.10.3/apache-tez-0.10.3-bin.tar.gz</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;mkdir -p /opt/tez&#x27;</span></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/apache-tez-0.10.3-bin.tar.gz <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/tez</span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;</span></span><br><span class="line"><span class="string">if ! hdfs dfs -ls /opt/tez/tez.tar.gz &gt; /dev/null 2&gt;&amp;1; then</span></span><br><span class="line"><span class="string">    rm -rf /opt/tez/apache-tez-0.10.3-bin</span></span><br><span class="line"><span class="string">    tar -zxf /opt/tez/apache-tez-0.10.3-bin.tar.gz -C /opt/tez</span></span><br><span class="line"><span class="string">    hdfs dfs -mkdir -p /opt/tez</span></span><br><span class="line"><span class="string">    hdfs dfs -put -f /opt/tez/apache-tez-0.10.3-bin/share/tez.tar.gz /opt/tez</span></span><br><span class="line"><span class="string">fi</span></span><br><span class="line"><span class="string">&#x27;</span></span><br><span class="line"></span><br><span class="line">HIVE_SITE_CONFIG_COMMON=$(<span class="built_in">cat</span> &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.tez.exec.inplace.progress&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/scratch_dir&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.user.install.directory&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/install_dir&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.runtime.optimize.local.fetch&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.exec.submit.local.task.via.child&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;yarn&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.local.mode&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.lib.uris&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/tez/tez.tar.gz&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.execution.engine&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;tez&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;metastore.warehouse.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/data/warehouse&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;metastore.metastore.event.db.notification.api.auth&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/hive-site-for-metastore.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    $&#123;HIVE_SITE_CONFIG_COMMON&#125;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/hive-site-for-hiveserver2.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;thrift://$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;:9083&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    $&#123;HIVE_SITE_CONFIG_COMMON&#125;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy hadoop config file to hive container</span></span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml /tmp/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml /tmp/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml /tmp/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml /tmp/mapred-site.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use customized entrypoint</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/updated_entrypoint.sh &lt;&lt; <span class="string">&#x27;EOF&#x27;</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;IS_RESUME=<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span></span><br><span class="line">FLAG_FILE=/opt/hive/already_init_schema</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span> ] || [ <span class="string">&quot;<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span> = <span class="string">&quot;false&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$&#123;FLAG_FILE&#125;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Skip init schema when restart.&quot;</span></span><br><span class="line">        IS_RESUME=<span class="literal">true</span> /entrypoint.sh</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Try to init schema for the first time.&quot;</span></span><br><span class="line">        <span class="built_in">touch</span> <span class="variable">$&#123;FLAG_FILE&#125;</span></span><br><span class="line">        IS_RESUME=<span class="literal">false</span> /entrypoint.sh</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Skip init schema for every time.&quot;</span></span><br><span class="line">    IS_RESUME=<span class="literal">true</span> /entrypoint.sh</span><br><span class="line"><span class="keyword">fi</span> </span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">chmod</span> a+x /tmp/updated_entrypoint.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start standalone metastore</span></span><br><span class="line">docker create --name <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -p 9083:9083 -e SERVICE_NAME=metastore --entrypoint /updated_entrypoint.sh apache/hive:4.0.0</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hive-site-for-metastore.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hive/conf/hive-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/core-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hdfs-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/yarn-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/mapred-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/updated_entrypoint.sh <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/updated_entrypoint.sh</span><br><span class="line"></span><br><span class="line">docker start <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start standalone hiveserver2</span></span><br><span class="line">docker create --name <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -p 10000:10000 -e SERVICE_NAME=hiveserver2 -e IS_RESUME=<span class="literal">true</span> apache/hive:4.0.0</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hive-site-for-hiveserver2.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hive/conf/hive-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/core-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hdfs-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/yarn-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/mapred-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml</span><br><span class="line"></span><br><span class="line">docker start <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span></span><br></pre></td></tr></table></figure>
<p>Test:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span> beeline -u <span class="string">&#x27;jdbc:hive2://localhost:10000/&#x27;</span> -e <span class="string">&quot;</span></span><br><span class="line"><span class="string">create table hive_example(a string, b int) partitioned by(c int);</span></span><br><span class="line"><span class="string">alter table hive_example add partition(c=1);</span></span><br><span class="line"><span class="string">insert into hive_example partition(c=1) values(&#x27;a&#x27;, 1), (&#x27;a&#x27;, 2),(&#x27;b&#x27;,3);</span></span><br><span class="line"><span class="string">select * from hive_example;</span></span><br><span class="line"><span class="string">drop table hive_example;</span></span><br><span class="line"><span class="string">&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="422-use-external-postgres"><a class="markdownIt-Anchor" href="#422-use-external-postgres"></a> 4.2.2 Use External Postgres</h3>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=hadoop-ns</span><br><span class="line">POSTGRES_CONTAINER_NAME=postgres</span><br><span class="line">POSTGRES_USER=<span class="string">&quot;hive_postgres&quot;</span></span><br><span class="line">POSTGRES_PASSWORD=<span class="string">&quot;Abcd1234&quot;</span></span><br><span class="line">POSTGRES_DB=<span class="string">&quot;hive-metastore&quot;</span></span><br><span class="line">HADOOP_CONTAINER_NAME=hadoop</span><br><span class="line">HIVE_PREFIX=hive-with-postgres</span><br><span class="line">HIVE_METASTORE_CONTAINER_NAME=<span class="variable">$&#123;HIVE_PREFIX&#125;</span>-metastore</span><br><span class="line">HIVE_SERVER_CONTAINER_NAME=<span class="variable">$&#123;HIVE_PREFIX&#125;</span>-server</span><br><span class="line">IS_RESUME=<span class="string">&quot;false&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># How to use sql:</span></span><br><span class="line"><span class="comment"># 1. docker exec -it $&#123;POSTGRES_CONTAINER_NAME&#125; bash</span></span><br><span class="line"><span class="comment"># 2. psql -U $&#123;POSTGRES_USER&#125; -d $&#123;POSTGRES_DB&#125;</span></span><br><span class="line">docker run --name <span class="variable">$&#123;POSTGRES_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> \</span><br><span class="line">    -e POSTGRES_USER=<span class="string">&quot;<span class="variable">$&#123;POSTGRES_USER&#125;</span>&quot;</span> \</span><br><span class="line">    -e POSTGRES_PASSWORD=<span class="string">&quot;<span class="variable">$&#123;POSTGRES_PASSWORD&#125;</span>&quot;</span> \</span><br><span class="line">    -e POSTGRES_DB=<span class="string">&quot;<span class="variable">$&#123;POSTGRES_DB&#125;</span>&quot;</span> \</span><br><span class="line">    -d postgres:17.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download tez resources and put to hdfs</span></span><br><span class="line"><span class="keyword">if</span> [ ! -e /tmp/apache-tez-0.10.3-bin.tar.gz ]; <span class="keyword">then</span></span><br><span class="line">    wget -O /tmp/apache-tez-0.10.3-bin.tar.gz  https://downloads.apache.org/tez/0.10.3/apache-tez-0.10.3-bin.tar.gz</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;mkdir -p /opt/tez&#x27;</span></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/apache-tez-0.10.3-bin.tar.gz <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/tez</span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;</span></span><br><span class="line"><span class="string">if ! hdfs dfs -ls /opt/tez/tez.tar.gz &gt; /dev/null 2&gt;&amp;1; then</span></span><br><span class="line"><span class="string">    rm -rf /opt/tez/apache-tez-0.10.3-bin</span></span><br><span class="line"><span class="string">    tar -zxf /opt/tez/apache-tez-0.10.3-bin.tar.gz -C /opt/tez</span></span><br><span class="line"><span class="string">    hdfs dfs -mkdir -p /opt/tez</span></span><br><span class="line"><span class="string">    hdfs dfs -put -f /opt/tez/apache-tez-0.10.3-bin/share/tez.tar.gz /opt/tez</span></span><br><span class="line"><span class="string">fi</span></span><br><span class="line"><span class="string">&#x27;</span></span><br><span class="line"></span><br><span class="line">HIVE_SITE_CONFIG_COMMON=$(<span class="built_in">cat</span> &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.tez.exec.inplace.progress&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/scratch_dir&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.user.install.directory&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/install_dir&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.runtime.optimize.local.fetch&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.exec.submit.local.task.via.child&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;yarn&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.local.mode&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.lib.uris&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/tez/tez.tar.gz&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.execution.engine&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;tez&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;metastore.warehouse.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/data/warehouse&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;metastore.metastore.event.db.notification.api.auth&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/hive-site-for-metastore.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;jdbc:postgresql://$&#123;POSTGRES_CONTAINER_NAME&#125;/$&#123;POSTGRES_DB&#125;&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;org.postgresql.Driver&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;$&#123;POSTGRES_USER&#125;&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;$&#123;POSTGRES_PASSWORD&#125;&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    $&#123;HIVE_SITE_CONFIG_COMMON&#125;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/hive-site-for-hiveserver2.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;thrift://$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;:9083&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    $&#123;HIVE_SITE_CONFIG_COMMON&#125;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy hadoop config file to hive container</span></span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml /tmp/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml /tmp/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml /tmp/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml /tmp/mapred-site.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare jdbc driver</span></span><br><span class="line"><span class="keyword">if</span> [ ! -e /tmp/postgresql-42.7.4.jar ]; <span class="keyword">then</span></span><br><span class="line">    wget -O /tmp/postgresql-42.7.4.jar  https://jdbc.postgresql.org/download/postgresql-42.7.4.jar</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use customized entrypoint</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/updated_entrypoint.sh &lt;&lt; <span class="string">&#x27;EOF&#x27;</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;IS_RESUME=<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span></span><br><span class="line">FLAG_FILE=/opt/hive/already_init_schema</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span> ] || [ <span class="string">&quot;<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span> = <span class="string">&quot;false&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$&#123;FLAG_FILE&#125;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Skip init schema when restart.&quot;</span></span><br><span class="line">        IS_RESUME=<span class="literal">true</span> /entrypoint.sh</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Try to init schema for the first time.&quot;</span></span><br><span class="line">        <span class="built_in">touch</span> <span class="variable">$&#123;FLAG_FILE&#125;</span></span><br><span class="line">        IS_RESUME=<span class="literal">false</span> /entrypoint.sh</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Skip init schema for every time.&quot;</span></span><br><span class="line">    IS_RESUME=<span class="literal">true</span> /entrypoint.sh</span><br><span class="line"><span class="keyword">fi</span> </span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">chmod</span> a+x /tmp/updated_entrypoint.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start standalone metastore</span></span><br><span class="line">docker create --name <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -p 9083:9083 -e SERVICE_NAME=metastore -e DB_DRIVER=postgres -e IS_RESUME=<span class="variable">$&#123;IS_RESUME&#125;</span> --entrypoint /updated_entrypoint.sh apache/hive:4.0.0</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hive-site-for-metastore.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hive/conf/hive-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/core-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hdfs-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/yarn-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/mapred-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/updated_entrypoint.sh <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/updated_entrypoint.sh</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/postgresql-42.7.4.jar <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hive/lib/postgresql-42.7.4.jar</span><br><span class="line"></span><br><span class="line">docker start <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start standalone hiveserver2</span></span><br><span class="line">docker create --name <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -p 10000:10000 -e SERVICE_NAME=hiveserver2 -e DB_DRIVER=postgres -e IS_RESUME=<span class="literal">true</span> apache/hive:4.0.0</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hive-site-for-hiveserver2.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hive/conf/hive-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/core-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hdfs-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/yarn-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/mapred-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/postgresql-42.7.4.jar <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hive/lib/postgresql-42.7.4.jar</span><br><span class="line"></span><br><span class="line">docker start <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span></span><br></pre></td></tr></table></figure>
<p>Test:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span> beeline -u <span class="string">&#x27;jdbc:hive2://localhost:10000/&#x27;</span> -e <span class="string">&quot;</span></span><br><span class="line"><span class="string">create table hive_example(a string, b int) partitioned by(c int);</span></span><br><span class="line"><span class="string">alter table hive_example add partition(c=1);</span></span><br><span class="line"><span class="string">insert into hive_example partition(c=1) values(&#x27;a&#x27;, 1), (&#x27;a&#x27;, 2),(&#x27;b&#x27;,3);</span></span><br><span class="line"><span class="string">select * from hive_example;</span></span><br><span class="line"><span class="string">drop table hive_example;</span></span><br><span class="line"><span class="string">&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="43-hive-metastore-demo"><a class="markdownIt-Anchor" href="#43-hive-metastore-demo"></a> 4.3 Hive Metastore Demo</h2>
<p><a target="_blank" rel="noopener" href="https://github.com/apache/hive/blob/master/standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift">hive_metastore.thrift</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> hive_metastore_demo</span><br><span class="line"><span class="built_in">cd</span> hive_metastore_demo</span><br><span class="line"></span><br><span class="line">wget https://raw.githubusercontent.com/apache/hive/master/standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift</span><br></pre></td></tr></table></figure>
<p>Modify <code>hive_metastore.thrift</code>, remove <code>fb</code> parts:</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">25,26d24</span><br><span class="line">&lt; include &quot;share/fb303/if/fb303.thrift&quot;</span><br><span class="line">&lt;</span><br><span class="line">2527c2525</span><br><span class="line">&lt; service ThriftHiveMetastore extends fb303.FacebookService</span><br><span class="line"><span class="comment">---</span></span><br><span class="line">&gt; service ThriftHiveMetastore</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">thrift --gen cpp hive_metastore.thrift</span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"></span><br><span class="line"><span class="comment"># create libhms.a</span></span><br><span class="line">gcc -o build/ThriftHiveMetastore.o -c gen-cpp/ThriftHiveMetastore.cpp -O3 -Wall -fPIC</span><br><span class="line">gcc -o build/hive_metastore_constants.o -c gen-cpp/hive_metastore_constants.cpp -O3 -Wall -fPIC</span><br><span class="line">gcc -o build/hive_metastore_types.o -c gen-cpp/hive_metastore_types.cpp -O3 -Wall -fPIC</span><br><span class="line">ar rcs build/libhms.a build/ThriftHiveMetastore.o build/hive_metastore_constants.o build/hive_metastore_types.o</span><br><span class="line"></span><br><span class="line"><span class="comment"># main.cpp</span></span><br><span class="line"><span class="built_in">cat</span> &gt; main.cpp &lt;&lt; <span class="string">&#x27;EOF&#x27;</span></span><br><span class="line"><span class="comment">#include &lt;thrift/protocol/TBinaryProtocol.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;thrift/transport/TSocket.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;thrift/transport/TTransportUtils.h&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include &quot;gen-cpp/ThriftHiveMetastore.h&quot;</span></span><br><span class="line"></span><br><span class="line">using namespace apache::thrift;</span><br><span class="line">using namespace apache::thrift::transport;</span><br><span class="line">using namespace apache::thrift::protocol;</span><br><span class="line"></span><br><span class="line">int main(int argc, char* argv[]) &#123;</span><br><span class="line">    <span class="keyword">if</span> (argc &lt; 4) &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;requires 4 arguments&quot;</span> &lt;&lt; <span class="string">std::endl;</span></span><br><span class="line"><span class="string">        return 1;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    const std</span>::string hms_ip = argv[1];</span><br><span class="line">    const int hms_port = std::atoi(argv[2]);</span><br><span class="line">    const std::string db_name = argv[3];</span><br><span class="line">    const std::string table_name = argv[4];</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;hms_ip: &quot;</span> &lt;&lt; <span class="string">hms_ip &lt;&lt; &quot;, hms_port: &quot; &lt;&lt; hms_port &lt;&lt; &quot;, db_name: &quot; &lt;&lt; db_name</span></span><br><span class="line"><span class="string">              &lt;&lt; &quot;, table_name: &quot; &lt;&lt; table_name &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    std::shared_ptr&lt;TTransport&gt; socket(new TSocket(hms_ip</span>, hms_port));</span><br><span class="line">    std::shared_ptr&lt;TTransport&gt; transport(new TBufferedTransport(socket));</span><br><span class="line">    std::shared_ptr&lt;TProtocol&gt; protocol(new TBinaryProtocol(transport));</span><br><span class="line">    Apache::Hadoop::Hive::ThriftHiveMetastoreClient client(protocol);</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        transport-&gt;open();</span><br><span class="line"></span><br><span class="line">        // Fetch and <span class="built_in">print</span> the list of databases</span><br><span class="line">        std::vector&lt;std::string&gt; databases;</span><br><span class="line">        client.get_all_databases(databases);</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Databases:&quot;</span> &lt;&lt; <span class="string">std::endl;</span></span><br><span class="line"><span class="string">        for (const auto&amp; db : databases) &#123;</span></span><br><span class="line"><span class="string">            std</span>::cout &lt;&lt; <span class="string">&quot;    &quot;</span> &lt;&lt; <span class="string">db &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        // Fetch and print the list of tables in a specific database</span></span><br><span class="line"><span class="string">        std::vector&lt;std::string&gt; tables;</span></span><br><span class="line"><span class="string">        client.get_all_tables(tables, db_name);</span></span><br><span class="line"><span class="string">        std::cout &lt;&lt; &quot;Tables in database &#x27;&quot; &lt;&lt; db_name &lt;&lt; &quot;&#x27;:&quot; &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">        for (const auto&amp; table : tables) &#123;</span></span><br><span class="line"><span class="string">            std::cout &lt;&lt; &quot;    &quot; &lt;&lt; table &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        // Fetch and print the details of a specific table</span></span><br><span class="line"><span class="string">        Apache::Hadoop::Hive::Table table;</span></span><br><span class="line"><span class="string">        client.get_table(table, db_name, table_name);</span></span><br><span class="line"><span class="string">        std::cout &lt;&lt; &quot;Table details for &#x27;&quot; &lt;&lt; table_name &lt;&lt; &quot;&#x27;:&quot; &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">        std::cout &lt;&lt; &quot;    Table name: &quot; &lt;&lt; table.tableName &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">        std::cout &lt;&lt; &quot;    Database name: &quot; &lt;&lt; table.dbName &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">        std::cout &lt;&lt; &quot;    Owner: &quot; &lt;&lt; table.owner &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">        std::cout &lt;&lt; &quot;    Create time: &quot; &lt;&lt; table.createTime &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">        std::cout &lt;&lt; &quot;    Location: &quot; &lt;&lt; table.sd.location &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        transport-&gt;close();</span></span><br><span class="line"><span class="string">    &#125; catch (TException&amp; tx) &#123;</span></span><br><span class="line"><span class="string">        std::cerr &lt;&lt; &quot;Exception occurred: &quot; &lt;&lt; tx.what() &lt;&lt; std::endl;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return 0;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">gcc -o build/main main.cpp -O3 -Lbuild -lhms -lstdc++ -std=gnu++17 -lthrift -lm</span></span><br><span class="line"><span class="string">build/main &lt;ip&gt; 9083 default hive_test_table</span></span><br></pre></td></tr></table></figure>
<h2 id="44-syntax"><a class="markdownIt-Anchor" href="#44-syntax"></a> 4.4 Syntax</h2>
<h3 id="441-partition"><a class="markdownIt-Anchor" href="#441-partition"></a> 4.4.1 Partition</h3>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sales (</span><br><span class="line">  sale_id <span class="type">INT</span>,</span><br><span class="line">  product STRING,</span><br><span class="line">  amount <span class="keyword">DOUBLE</span></span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (<span class="keyword">year</span> <span class="type">INT</span>, <span class="keyword">month</span> <span class="type">INT</span>)</span><br><span class="line">STORED <span class="keyword">AS</span> PARQUET;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> sales <span class="keyword">PARTITION</span> (<span class="keyword">year</span><span class="operator">=</span><span class="number">2023</span>, <span class="keyword">month</span><span class="operator">=</span><span class="number">6</span>)</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line">  (<span class="number">1</span>, <span class="string">&#x27;Product A&#x27;</span>, <span class="number">100.0</span>),</span><br><span class="line">  (<span class="number">2</span>, <span class="string">&#x27;Product B&#x27;</span>, <span class="number">150.0</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="string">&#x27;Product C&#x27;</span>, <span class="number">200.0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> sales <span class="keyword">PARTITION</span> (<span class="keyword">year</span><span class="operator">=</span><span class="number">2023</span>, <span class="keyword">month</span><span class="operator">=</span><span class="number">7</span>)</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line">  (<span class="number">4</span>, <span class="string">&#x27;Product D&#x27;</span>, <span class="number">120.0</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="string">&#x27;Product E&#x27;</span>, <span class="number">130.0</span>),</span><br><span class="line">  (<span class="number">6</span>, <span class="string">&#x27;Product F&#x27;</span>, <span class="number">140.0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> sales;</span><br></pre></td></tr></table></figure>
<h1 id="5-flink"><a class="markdownIt-Anchor" href="#5-flink"></a> 5 Flink</h1>
<p>Here’s a example of how to use <a target="_blank" rel="noopener" href="https://github.com/big-data-europe/docker-spark">docker-spark</a> to start a flink cluster and do some tests.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/big-data-europe/docker-flink.git</span><br><span class="line"><span class="built_in">cd</span> docker-flink</span><br><span class="line">docker-compose up -d</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; person.csv &lt;&lt; <span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">1,<span class="string">&quot;Tom&quot;</span>,18</span><br><span class="line">2,<span class="string">&quot;Jerry&quot;</span>,19</span><br><span class="line">3,<span class="string">&quot;Spike&quot;</span>,20</span><br><span class="line">4,<span class="string">&quot;Tyke&quot;</span>,21</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> flink-master <span class="built_in">mkdir</span> -p /opt/data</span><br><span class="line">docker <span class="built_in">exec</span> flink-worker <span class="built_in">mkdir</span> -p /opt/data</span><br><span class="line">docker <span class="built_in">cp</span> person.csv flink-master:/opt/data/person.csv</span><br><span class="line">docker <span class="built_in">cp</span> person.csv flink-worker:/opt/data/person.csv</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> -it flink-master bash</span><br><span class="line">sql-client.sh</span><br><span class="line"></span><br><span class="line">CREATE TABLE person (</span><br><span class="line">    <span class="built_in">id</span> INT,</span><br><span class="line">    name STRING,</span><br><span class="line">    age INT</span><br><span class="line">) WITH (</span><br><span class="line">    <span class="string">&#x27;connector&#x27;</span> = <span class="string">&#x27;filesystem&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;path&#x27;</span> = <span class="string">&#x27;file:///opt/data/person.csv&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;format&#x27;</span> = <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">SELECT * FROM person;</span><br></pre></td></tr></table></figure>
<h1 id="6-docker-compose"><a class="markdownIt-Anchor" href="#6-docker-compose"></a> 6 Docker-Compose</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/big-data-europe">Big Data Europe</a>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/big-data-europe/docker-hadoop">docker-hadoop</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/big-data-europe/docker-hive">docker-hive</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/big-data-europe/docker-spark">docker-spark</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/big-data-europe/docker-flink">docker-flink</a></li>
</ul>
</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%8E%9F%E5%88%9B/" rel="tag"># 原创</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/07/10/DBMS-Trivial/" rel="prev" title="DBMS-Trivial">
      <i class="fa fa-chevron-left"></i> DBMS-Trivial
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/07/18/ClickHouse-Trial/" rel="next" title="ClickHouse-Trial">
      ClickHouse-Trial <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
      <div class="tabs tabs-comment">
        <ul class="nav-tabs">
            <li class="tab"><a href="#comment-livere">livere</a></li>
            <li class="tab"><a href="#comment-valine">valine</a></li>
        </ul>
        <div class="tab-content">
            <div class="tab-pane livere" id="comment-livere">
              
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC8zMzY0My8xMDE5OA=="></div>
  </div>
  
            </div>
            <div class="tab-pane valine" id="comment-valine">
              <div class="comments" id="valine-comments"></div>
            </div>
        </div>
      </div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-overview"><span class="nav-text"> 1 Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-hdfs"><span class="nav-text"> 2 HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#21-deployment-via-docker"><span class="nav-text"> 2.1 Deployment via Docker</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#22-deployment-via-docker-and-kerberos"><span class="nav-text"> 2.2 Deployment via Docker and Kerberos</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#221-kerberos-basics"><span class="nav-text"> 2.2.1 Kerberos Basics</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#222-kerberos-container"><span class="nav-text"> 2.2.2 Kerberos Container</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#223-hadoop-container"><span class="nav-text"> 2.2.3 Hadoop Container</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#23-configuration"><span class="nav-text"> 2.3 Configuration</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#231-how-to-config-dfsnameservices"><span class="nav-text"> 2.3.1 How to config dfs.nameservices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#232-support-config-hot-loading"><span class="nav-text"> 2.3.2 Support config hot loading</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#233-hedge-read"><span class="nav-text"> 2.3.3 Hedge read</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#24-command"><span class="nav-text"> 2.4 Command</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#241-daemon"><span class="nav-text"> 2.4.1 daemon</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#242-hdfs"><span class="nav-text"> 2.4.2 hdfs</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2421-file-path"><span class="nav-text"> 2.4.2.1 File Path</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2422-file-status"><span class="nav-text"> 2.4.2.2 File Status</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2423-show-content"><span class="nav-text"> 2.4.2.3 Show Content</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2424-grant-permission"><span class="nav-text"> 2.4.2.4 Grant Permission</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#243-yarn"><span class="nav-text"> 2.4.3 yarn</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2431-node"><span class="nav-text"> 2.4.3.1 Node</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2432-application"><span class="nav-text"> 2.4.3.2 Application</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#25-tips"><span class="nav-text"> 2.5 Tips</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#251-how-to-access-a-hadoop-cluster-started-via-docker"><span class="nav-text"> 2.5.1 How to access a hadoop cluster started via docker</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#252-sdk-dont-recognize-hadoop_conf_dir-automatically"><span class="nav-text"> 2.5.2 SDK don’t recognize HADOOP_CONF_DIR automatically</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-spark"><span class="nav-text"> 3 Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#31-deployment"><span class="nav-text"> 3.1 Deployment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#32-tips"><span class="nav-text"> 3.2 Tips</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#321-spark-sql"><span class="nav-text"> 3.2.1 Spark-Sql</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#322-spark-shell"><span class="nav-text"> 3.2.2 Spark-Shell</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3221-read-parquetorcavro-file"><span class="nav-text"> 3.2.2.1 Read parquet&#x2F;orc&#x2F;avro file</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-hive"><span class="nav-text"> 4 Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#41-components"><span class="nav-text"> 4.1 Components</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#411-hive-server-2-hs2"><span class="nav-text"> 4.1.1 Hive-Server 2 (HS2)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#412-hive-metastore-server-hms"><span class="nav-text"> 4.1.2 Hive Metastore Server (HMS)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#42-deployment-via-docker"><span class="nav-text"> 4.2 Deployment via Docker</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#421-use-built-in-derby"><span class="nav-text"> 4.2.1 Use built-in Derby</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#422-use-external-postgres"><span class="nav-text"> 4.2.2 Use External Postgres</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#43-hive-metastore-demo"><span class="nav-text"> 4.3 Hive Metastore Demo</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#44-syntax"><span class="nav-text"> 4.4 Syntax</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#441-partition"><span class="nav-text"> 4.4.1 Partition</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-flink"><span class="nav-text"> 5 Flink</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-docker-compose"><span class="nav-text"> 6 Docker-Compose</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Liuyehcf"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Liuyehcf</p>
  <div class="site-description" itemprop="description">大音希声，大象无形</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">285</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">99</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liuyehcf</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qhEhLuMeMOy1zgcBhkqUS6P8-gzGzoHsz',
      appKey     : 'uhkruDLNLNdL5rQjRBY2X9Ke',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
