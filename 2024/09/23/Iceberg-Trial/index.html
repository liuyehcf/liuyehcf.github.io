<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="阅读更多">
<meta property="og:type" content="article">
<meta property="og:title" content="Iceberg-Trial">
<meta property="og:url" content="http://example.com/2024/09/23/Iceberg-Trial/index.html">
<meta property="og:site_name" content="Liuye Notebook">
<meta property="og:description" content="阅读更多">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-09-23T06:43:47.000Z">
<meta property="article:modified_time" content="2024-10-25T08:46:15.000Z">
<meta property="article:author" content="Liuyehcf">
<meta property="article:tag" content="原创">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2024/09/23/Iceberg-Trial/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Iceberg-Trial | Liuye Notebook</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Liuye Notebook</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-explore">

    <a href="/explore/" rel="section"><i class="fa fa-sitemap fa-fw"></i>发现</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/09/23/Iceberg-Trial/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Liuyehcf">
      <meta itemprop="description" content="大音希声，大象无形">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liuye Notebook">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Iceberg-Trial
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-09-23 14:43:47" itemprop="dateCreated datePublished" datetime="2024-09-23T14:43:47+08:00">2024-09-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-10-25 16:46:15" itemprop="dateModified" datetime="2024-10-25T16:46:15+08:00">2024-10-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Database/" itemprop="url" rel="index"><span itemprop="name">Database</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Database/Lakehouse/" itemprop="url" rel="index"><span itemprop="name">Lakehouse</span></a>
                </span>
            </span>

          
            <span id="/2024/09/23/Iceberg-Trial/" class="post-meta-item leancloud_visitors" data-flag-title="Iceberg-Trial" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2024/09/23/Iceberg-Trial/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/09/23/Iceberg-Trial/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>阅读更多</strong></p>
<span id="more"></span>
<h1 id="1-killing-feature"><a class="markdownIt-Anchor" href="#1-killing-feature"></a> 1 Killing Feature</h1>
<h1 id="2-spark-iceberg"><a class="markdownIt-Anchor" href="#2-spark-iceberg"></a> 2 Spark &amp; Iceberg</h1>
<h2 id="21-step1-create-a-shared-network"><a class="markdownIt-Anchor" href="#21-step1-create-a-shared-network"></a> 2.1 Step1: Create a shared network</h2>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a network to be used by both spark and hadoop</span></span><br><span class="line">SHARED_NS=iceberg-ns</span><br><span class="line">docker network create <span class="variable">$&#123;SHARED_NS&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="22-step2-start-hadoop"><a class="markdownIt-Anchor" href="#22-step2-start-hadoop"></a> 2.2 Step2: Start Hadoop</h2>
<p>Start a single-node hadoop cluster joining the shared network.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=iceberg-ns</span><br><span class="line">HADOOP_CONTAINER_NAME=iceberg-hadoop</span><br><span class="line"></span><br><span class="line">docker run -dit --name <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -p 8020:8020 -p 9866:9866 -p 8042:8042 -p 8088:8088 apache/hadoop:3.3.6 bash</span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/core-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;hdfs://<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:8020&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/hdfs-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;dfs.replication&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;1&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;dfs.datanode.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:9866&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;dfs.datanode.http.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:9864&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:9867&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;dfs.datanode.hostname&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/yarn-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">  &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;8192&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;4&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;1024&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;8192&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&quot;cat &gt; /opt/hadoop/etc/hadoop/mapred-site.xml &lt;&lt; EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;yarn&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;/opt/hadoop/share/hadoop/mapreduce/*,/opt/hadoop/share/hadoop/mapreduce/lib/*&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Format</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs namenode -format&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># retart all daemons</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs --daemon stop namenode; hdfs --daemon start namenode&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs --daemon stop datanode; hdfs --daemon start datanode&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;yarn --daemon stop resourcemanager; yarn --daemon start resourcemanager&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;yarn --daemon stop nodemanager; yarn --daemon start nodemanager&#x27;</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;mapred --daemon stop historyserver; mapred --daemon start historyserver&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Report status</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hdfs dfsadmin -report&#x27;</span></span><br></pre></td></tr></table></figure>
<p>Test:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar pi 10 100&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="23-step3-start-spark"><a class="markdownIt-Anchor" href="#23-step3-start-spark"></a> 2.3 Step3: Start Spark</h2>
<p>Start a spark container joining the shared network.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=iceberg-ns</span><br><span class="line">HADOOP_CONTAINER_NAME=iceberg-hadoop</span><br><span class="line">SPARK_CONTAINER_NAME=iceberg-spark</span><br><span class="line"></span><br><span class="line">docker run -dit --name <span class="variable">$&#123;SPARK_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -e HADOOP_CONTAINER_NAME=<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> spark:3.5.2-scala2.12-java17-python3-ubuntu bash</span><br><span class="line"><span class="comment"># Setup home directory for user spark, otherwise spark&#x27;s package installation mechanism won&#x27;t work, which will store jars in directory: /home/spark/.ivy2/cache</span></span><br><span class="line">docker <span class="built_in">exec</span> -u root <span class="variable">$&#123;SPARK_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;mkdir -p /home/spark; chmod 755 /home/spark; chown -R spark:spark /home/spark&#x27;</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> -it <span class="variable">$&#123;SPARK_CONTAINER_NAME&#125;</span> /opt/spark/bin/spark-sql \</span><br><span class="line">    --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1 \</span><br><span class="line">    --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \</span><br><span class="line">    --conf spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog \</span><br><span class="line">    --conf spark.sql.catalog.spark_catalog.type=hive \</span><br><span class="line">    --conf spark.sql.catalog.iceberg_spark_demo=org.apache.iceberg.spark.SparkCatalog \</span><br><span class="line">    --conf spark.sql.catalog.iceberg_spark_demo.type=hadoop \</span><br><span class="line">    --conf spark.sql.catalog.iceberg_spark_demo.warehouse=hdfs://<span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>/user/spark/warehouse</span><br></pre></td></tr></table></figure>
<p>Test:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> iceberg_spark_demo.db.table (id <span class="type">bigint</span>, data string) <span class="keyword">USING</span> iceberg;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> iceberg_spark_demo.db.table <span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="string">&#x27;a&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;b&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;c&#x27;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> iceberg_spark_demo.db.table;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> iceberg_spark_demo.db.table <span class="keyword">ADD</span> COLUMNS (age <span class="type">INT</span> COMMENT <span class="string">&#x27;Age of the record&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> iceberg_spark_demo.db.table <span class="keyword">VALUES</span> (<span class="number">4</span>, <span class="string">&#x27;d&#x27;</span>, <span class="number">25</span>), (<span class="number">5</span>, <span class="string">&#x27;e&#x27;</span>, <span class="number">30</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> iceberg_spark_demo.db.table;</span><br><span class="line"><span class="comment">-- Spark cannot drop a column; it can only redefine all columns. This is equivalent to deleting all columns and then adding two columns with the same names as before. However, they are actually different columns (the IDs are different).</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> iceberg_spark_demo.db.table REPLACE COLUMNS (id <span class="type">BIGINT</span>, data STRING);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> iceberg_spark_demo.db.table <span class="keyword">VALUES</span> (<span class="number">6</span>, <span class="string">&#x27;f&#x27;</span>), (<span class="number">7</span>, <span class="string">&#x27;g&#x27;</span>);</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> iceberg_spark_demo.db.table RENAME <span class="keyword">COLUMN</span> data <span class="keyword">TO</span> description;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> iceberg_spark_demo.db.table <span class="keyword">VALUES</span> (<span class="number">8</span>, <span class="string">&#x27;h&#x27;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> iceberg_spark_demo.db.table;</span><br></pre></td></tr></table></figure>
<h1 id="3-trino-iceberg"><a class="markdownIt-Anchor" href="#3-trino-iceberg"></a> 3 Trino &amp; Iceberg</h1>
<p>Trino only support hive-metastore based catalog rather than raw hadoop filesystem based catalog.</p>
<h2 id="31-step1-step2"><a class="markdownIt-Anchor" href="#31-step1-step2"></a> 3.1 Step1 &amp; Step2</h2>
<p>We can use the same container and network created in section <a href="#21-step1-create-a-shared-network">Step1: Create a shared network</a> and <a href="#22-step2-start-hadoop">Step2: Start a hadoop as storage of iceberg</a></p>
<h2 id="32-step3-start-hive"><a class="markdownIt-Anchor" href="#32-step3-start-hive"></a> 3.2 Step3: Start Hive</h2>
<p><a target="_blank" rel="noopener" href="https://hive.apache.org/developement/quickstart/">Apache Hive - Quickstart</a></p>
<p>Start a hive container joining the shared network.</p>
<ul>
<li><strong>Tez-tips: Don’t use <code>apache-tez-0.10.3-bin.tar.gz</code> directly but use <code>share/tez.tar.gz</code> after uncompressing. (<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/72211046/error-could-not-find-or-load-main-class-org-apache-tez-dag-app-dagappmaster">Error: Could not find or load main class org.apache.tez.dag.app.DAGAppMaster</a>)</strong></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=iceberg-ns</span><br><span class="line">POSTGRES_CONTAINER_NAME=iceberg-postgres</span><br><span class="line">POSTGRES_USER=<span class="string">&quot;hive_postgres&quot;</span></span><br><span class="line">POSTGRES_PASSWORD=<span class="string">&quot;Abcd1234&quot;</span></span><br><span class="line">POSTGRES_DB=<span class="string">&quot;hive-metastore&quot;</span></span><br><span class="line">HADOOP_CONTAINER_NAME=iceberg-hadoop</span><br><span class="line">HIVE_PREFIX=iceberg-hive-with-postgres</span><br><span class="line">HIVE_METASTORE_CONTAINER_NAME=<span class="variable">$&#123;HIVE_PREFIX&#125;</span>-metastore</span><br><span class="line">HIVE_SERVER_CONTAINER_NAME=<span class="variable">$&#123;HIVE_PREFIX&#125;</span>-server</span><br><span class="line">IS_RESUME=<span class="string">&quot;false&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># How to use sql:</span></span><br><span class="line"><span class="comment"># 1. docker exec -it $&#123;POSTGRES_CONTAINER_NAME&#125; bash</span></span><br><span class="line"><span class="comment"># 2. psql -U $&#123;POSTGRES_USER&#125; -d $&#123;POSTGRES_DB&#125;</span></span><br><span class="line">docker run --name <span class="variable">$&#123;POSTGRES_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> \</span><br><span class="line">    -e POSTGRES_USER=<span class="string">&quot;<span class="variable">$&#123;POSTGRES_USER&#125;</span>&quot;</span> \</span><br><span class="line">    -e POSTGRES_PASSWORD=<span class="string">&quot;<span class="variable">$&#123;POSTGRES_PASSWORD&#125;</span>&quot;</span> \</span><br><span class="line">    -e POSTGRES_DB=<span class="string">&quot;<span class="variable">$&#123;POSTGRES_DB&#125;</span>&quot;</span> \</span><br><span class="line">    -d postgres:17.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download tez resources and put to hdfs</span></span><br><span class="line"><span class="keyword">if</span> [ ! -e /tmp/apache-tez-0.10.3-bin.tar.gz ]; <span class="keyword">then</span></span><br><span class="line">    wget -O /tmp/apache-tez-0.10.3-bin.tar.gz  https://downloads.apache.org/tez/0.10.3/apache-tez-0.10.3-bin.tar.gz</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;mkdir -p /opt/tez&#x27;</span></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/apache-tez-0.10.3-bin.tar.gz <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/tez</span><br><span class="line">docker <span class="built_in">exec</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span> bash -c <span class="string">&#x27;</span></span><br><span class="line"><span class="string">if ! hdfs dfs -ls /opt/tez/tez.tar.gz &gt; /dev/null 2&gt;&amp;1; then</span></span><br><span class="line"><span class="string">    rm -rf /opt/tez/apache-tez-0.10.3-bin</span></span><br><span class="line"><span class="string">    tar -zxf /opt/tez/apache-tez-0.10.3-bin.tar.gz -C /opt/tez</span></span><br><span class="line"><span class="string">    hdfs dfs -mkdir -p /opt/tez</span></span><br><span class="line"><span class="string">    hdfs dfs -put -f /opt/tez/apache-tez-0.10.3-bin/share/tez.tar.gz /opt/tez</span></span><br><span class="line"><span class="string">fi</span></span><br><span class="line"><span class="string">&#x27;</span></span><br><span class="line"></span><br><span class="line">HIVE_SITE_CONFIG_COMMON=$(<span class="built_in">cat</span> &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.tez.exec.inplace.progress&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/scratch_dir&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.user.install.directory&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/install_dir&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.runtime.optimize.local.fetch&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.exec.submit.local.task.via.child&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;yarn&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.local.mode&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;tez.lib.uris&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/tez/tez.tar.gz&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.execution.engine&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;tez&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;metastore.warehouse.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/opt/$&#123;HIVE_PREFIX&#125;/data/warehouse&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;metastore.metastore.event.db.notification.api.auth&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/hive-site-for-metastore.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;jdbc:postgresql://$&#123;POSTGRES_CONTAINER_NAME&#125;/$&#123;POSTGRES_DB&#125;&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;org.postgresql.Driver&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;$&#123;POSTGRES_USER&#125;&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;$&#123;POSTGRES_PASSWORD&#125;&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    $&#123;HIVE_SITE_CONFIG_COMMON&#125;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/hive-site-for-hiveserver2.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;thrift://$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;:9083&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    $&#123;HIVE_SITE_CONFIG_COMMON&#125;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy hadoop config file to hive container</span></span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml /tmp/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml /tmp/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml /tmp/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> <span class="variable">$&#123;HADOOP_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml /tmp/mapred-site.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare jdbc driver</span></span><br><span class="line"><span class="keyword">if</span> [ ! -e /tmp/postgresql-42.7.4.jar ]; <span class="keyword">then</span></span><br><span class="line">    wget -O /tmp/postgresql-42.7.4.jar  https://jdbc.postgresql.org/download/postgresql-42.7.4.jar</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use customized entrypoint</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/updated_entrypoint.sh &lt;&lt; <span class="string">&#x27;EOF&#x27;</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;IS_RESUME=<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span></span><br><span class="line">FLAG_FILE=/opt/hive/already_init_schema</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span> ] || [ <span class="string">&quot;<span class="variable">$&#123;IS_RESUME&#125;</span>&quot;</span> = <span class="string">&quot;false&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$&#123;FLAG_FILE&#125;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Skip init schema when restart.&quot;</span></span><br><span class="line">        IS_RESUME=<span class="literal">true</span> /entrypoint.sh</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Try to init schema for the first time.&quot;</span></span><br><span class="line">        <span class="built_in">touch</span> <span class="variable">$&#123;FLAG_FILE&#125;</span></span><br><span class="line">        IS_RESUME=<span class="literal">false</span> /entrypoint.sh</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Skip init schema for every time.&quot;</span></span><br><span class="line">    IS_RESUME=<span class="literal">true</span> /entrypoint.sh</span><br><span class="line"><span class="keyword">fi</span> </span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">chmod</span> a+x /tmp/updated_entrypoint.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start standalone metastore</span></span><br><span class="line">docker create --name <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -p 9083:9083 -e SERVICE_NAME=metastore -e DB_DRIVER=postgres -e IS_RESUME=<span class="variable">$&#123;IS_RESUME&#125;</span> --entrypoint /updated_entrypoint.sh apache/hive:4.0.0</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hive-site-for-metastore.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hive/conf/hive-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/core-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hdfs-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/yarn-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/mapred-site.xml <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/updated_entrypoint.sh <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/updated_entrypoint.sh</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/postgresql-42.7.4.jar <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span>:/opt/hive/lib/postgresql-42.7.4.jar</span><br><span class="line"></span><br><span class="line">docker start <span class="variable">$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start standalone hiveserver2</span></span><br><span class="line">docker create --name <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -p 10000:10000 -e SERVICE_NAME=hiveserver2 -e DB_DRIVER=postgres -e IS_RESUME=<span class="literal">true</span> apache/hive:4.0.0</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hive-site-for-hiveserver2.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hive/conf/hive-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/core-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/core-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/hdfs-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/yarn-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/mapred-site.xml <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hadoop/etc/hadoop/mapred-site.xml</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/postgresql-42.7.4.jar <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span>:/opt/hive/lib/postgresql-42.7.4.jar</span><br><span class="line"></span><br><span class="line">docker start <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span></span><br></pre></td></tr></table></figure>
<p>Test:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it <span class="variable">$&#123;HIVE_SERVER_CONTAINER_NAME&#125;</span> beeline -u <span class="string">&#x27;jdbc:hive2://localhost:10000/&#x27;</span> -e <span class="string">&quot;</span></span><br><span class="line"><span class="string">create table hive_example(a string, b int) partitioned by(c int);</span></span><br><span class="line"><span class="string">alter table hive_example add partition(c=1);</span></span><br><span class="line"><span class="string">insert into hive_example partition(c=1) values(&#x27;a&#x27;, 1), (&#x27;a&#x27;, 2),(&#x27;b&#x27;,3);</span></span><br><span class="line"><span class="string">select * from hive_example;</span></span><br><span class="line"><span class="string">drop table hive_example;</span></span><br><span class="line"><span class="string">&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="33-step4-start-trino"><a class="markdownIt-Anchor" href="#33-step4-start-trino"></a> 3.3 Step4: Start Trino</h2>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">SHARED_NS=iceberg-ns</span><br><span class="line">HADOOP_CONTAINER_NAME=iceberg-hadoop</span><br><span class="line">HIVE_PREFIX=iceberg-hive-with-postgres</span><br><span class="line">HIVE_METASTORE_CONTAINER_NAME=<span class="variable">$&#123;HIVE_PREFIX&#125;</span>-metastore</span><br><span class="line">HIVE_SERVER_CONTAINER_NAME=<span class="variable">$&#123;HIVE_PREFIX&#125;</span>-server</span><br><span class="line">TRINO_CONTAINER_NAME=iceberg-trino</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /tmp/trino-iceberg.properties &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">connector.name=iceberg</span></span><br><span class="line"><span class="string">hive.metastore.uri=thrift://$&#123;HIVE_METASTORE_CONTAINER_NAME&#125;:9083</span></span><br><span class="line"><span class="string">fs.hadoop.enabled=true</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">docker create --name <span class="variable">$&#123;TRINO_CONTAINER_NAME&#125;</span> --network <span class="variable">$&#123;SHARED_NS&#125;</span> -p 5005:5005 trinodb/trino:449</span><br><span class="line">docker <span class="built_in">cp</span> /tmp/trino-iceberg.properties <span class="variable">$&#123;TRINO_CONTAINER_NAME&#125;</span>:/etc/trino/catalog/iceberg.properties</span><br><span class="line">docker start <span class="variable">$&#123;TRINO_CONTAINER_NAME&#125;</span></span><br></pre></td></tr></table></figure>
<p>Test:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it <span class="variable">$&#123;TRINO_CONTAINER_NAME&#125;</span> trino --catalog iceberg --execute <span class="string">&quot;</span></span><br><span class="line"><span class="string">CREATE SCHEMA IF NOT EXISTS iceberg_trino_demo;</span></span><br><span class="line"><span class="string">DROP TABLE IF EXISTS iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string">CREATE TABLE iceberg_trino_demo.test_table (</span></span><br><span class="line"><span class="string">    id INTEGER, </span></span><br><span class="line"><span class="string">    data VARCHAR, </span></span><br><span class="line"><span class="string">    date DATE</span></span><br><span class="line"><span class="string">) WITH (</span></span><br><span class="line"><span class="string">    format = &#x27;PARQUET&#x27;,</span></span><br><span class="line"><span class="string">    partitioning = ARRAY[&#x27;date&#x27;]</span></span><br><span class="line"><span class="string">);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">INSERT INTO iceberg_trino_demo.test_table (id, data, date) VALUES </span></span><br><span class="line"><span class="string">(1, &#x27;sample1&#x27;, DATE &#x27;2024-09-01&#x27;),</span></span><br><span class="line"><span class="string">(2, &#x27;sample2&#x27;, DATE &#x27;2024-09-02&#x27;),</span></span><br><span class="line"><span class="string">(3, &#x27;sample3&#x27;, DATE &#x27;2024-09-03&#x27;);</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Delete data where id = 1</span></span><br><span class="line"><span class="string">DELETE FROM iceberg_trino_demo.test_table WHERE id = 1;</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Insert new data after delete</span></span><br><span class="line"><span class="string">INSERT INTO iceberg_trino_demo.test_table (id, data, date) VALUES </span></span><br><span class="line"><span class="string">(4, &#x27;sample4&#x27;, DATE &#x27;2024-09-04&#x27;),</span></span><br><span class="line"><span class="string">(5, &#x27;sample5&#x27;, DATE &#x27;2024-09-05&#x27;),</span></span><br><span class="line"><span class="string">(6, &#x27;sample6&#x27;, DATE &#x27;2024-09-06&#x27;);</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Add new column</span></span><br><span class="line"><span class="string">ALTER TABLE iceberg_trino_demo.test_table ADD COLUMN new_column VARCHAR;</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Insert new data after adding column</span></span><br><span class="line"><span class="string">INSERT INTO iceberg_trino_demo.test_table (id, data, date, new_column) VALUES </span></span><br><span class="line"><span class="string">(7, &#x27;sample7&#x27;, DATE &#x27;2024-09-07&#x27;, &#x27;extra1&#x27;),</span></span><br><span class="line"><span class="string">(8, &#x27;sample8&#x27;, DATE &#x27;2024-09-08&#x27;, &#x27;extra2&#x27;),</span></span><br><span class="line"><span class="string">(9, &#x27;sample9&#x27;, DATE &#x27;2024-09-09&#x27;, &#x27;extra3&#x27;);</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Drop the column</span></span><br><span class="line"><span class="string">ALTER TABLE iceberg_trino_demo.test_table DROP COLUMN new_column;</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Insert new data after dropping column</span></span><br><span class="line"><span class="string">INSERT INTO iceberg_trino_demo.test_table (id, data, date) VALUES </span></span><br><span class="line"><span class="string">(10, &#x27;sample10&#x27;, DATE &#x27;2024-09-10&#x27;),</span></span><br><span class="line"><span class="string">(11, &#x27;sample11&#x27;, DATE &#x27;2024-09-11&#x27;),</span></span><br><span class="line"><span class="string">(12, &#x27;sample12&#x27;, DATE &#x27;2024-09-12&#x27;);</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Rename column</span></span><br><span class="line"><span class="string">ALTER TABLE iceberg_trino_demo.test_table RENAME COLUMN data TO info;</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Insert new data after renaming column</span></span><br><span class="line"><span class="string">INSERT INTO iceberg_trino_demo.test_table (id, info, date) VALUES </span></span><br><span class="line"><span class="string">(13, &#x27;sample13&#x27;, DATE &#x27;2024-09-13&#x27;),</span></span><br><span class="line"><span class="string">(14, &#x27;sample14&#x27;, DATE &#x27;2024-09-14&#x27;),</span></span><br><span class="line"><span class="string">(15, &#x27;sample15&#x27;, DATE &#x27;2024-09-15&#x27;);</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Change column type</span></span><br><span class="line"><span class="string">ALTER TABLE iceberg_trino_demo.test_table ALTER COLUMN id SET DATA TYPE BIGINT;</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-- Insert new data after changing column type</span></span><br><span class="line"><span class="string">INSERT INTO iceberg_trino_demo.test_table (id, info, date) VALUES </span></span><br><span class="line"><span class="string">(16, &#x27;sample16&#x27;, DATE &#x27;2024-09-16&#x27;),</span></span><br><span class="line"><span class="string">(17, &#x27;sample17&#x27;, DATE &#x27;2024-09-17&#x27;),</span></span><br><span class="line"><span class="string">(18, &#x27;sample18&#x27;, DATE &#x27;2024-09-18&#x27;);</span></span><br><span class="line"><span class="string">SELECT * FROM iceberg_trino_demo.test_table;</span></span><br><span class="line"><span class="string">&quot;</span></span><br></pre></td></tr></table></figure>
<h1 id="4-api-demo"><a class="markdownIt-Anchor" href="#4-api-demo"></a> 4 API-Demo</h1>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;iceberg.version&gt;1.6.1&lt;/iceberg.version&gt;</span><br><span class="line">    &lt;parquet.version&gt;1.13.1&lt;/parquet.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.iceberg&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;iceberg-api&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;iceberg.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.iceberg&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;iceberg-bundled-guava&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;iceberg.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.iceberg&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;iceberg-common&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;iceberg.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.iceberg&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;iceberg-core&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;iceberg.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.iceberg&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;iceberg-hive-metastore&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;iceberg.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.iceberg&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;iceberg-parquet&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;iceberg.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.iceberg&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;iceberg-aws&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;iceberg.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.parquet&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;parquet-common&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;parquet.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.parquet&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;parquet-column&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;parquet.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.byconity.iceberg;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.compress.utils.Lists;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Sets;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.catalog.Namespace;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.catalog.TableIdentifier;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.data.GenericRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.data.Record;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.data.parquet.GenericParquetReaders;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.data.parquet.GenericParquetWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.deletes.EqualityDeleteWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.deletes.PositionDelete;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.deletes.PositionDeleteWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.hadoop.HadoopCatalog;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.io.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.parquet.Parquet;</span><br><span class="line"><span class="keyword">import</span> org.apache.iceberg.types.Types;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.Closeable;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">IceBergDemo</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">Schema</span> <span class="variable">POSITIONAL_DELETE_SCHEMA</span> <span class="operator">=</span></span><br><span class="line">            <span class="comment">// Those field ids are reserved</span></span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Schema</span>(Types.NestedField.required(<span class="number">2147483546</span>, <span class="string">&quot;file_path&quot;</span>, Types.StringType.get()),</span><br><span class="line">                    Types.NestedField.required(<span class="number">2147483545</span>, <span class="string">&quot;pos&quot;</span>, Types.LongType.get()));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Configuration hdfsConf;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Path warehousePath;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Record&gt; records = Lists.newArrayList();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> HadoopCatalog hadoopCatalog;</span><br><span class="line">    <span class="keyword">private</span> Table table;</span><br><span class="line">    <span class="keyword">private</span> String dataFilePath;</span><br><span class="line">    <span class="keyword">private</span> Schema idEqdeleteSchema;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">IceBergDemo</span><span class="params">(String host, <span class="type">int</span> port)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.hdfsConf = <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="built_in">this</span>.hdfsConf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, String.format(<span class="string">&quot;hdfs://%s:%d&quot;</span>, host, port));</span><br><span class="line">        <span class="comment">// Use full path here, including the protocol, otherwise, spark cannot parse metadata</span></span><br><span class="line">        <span class="comment">// correctly</span></span><br><span class="line">        <span class="built_in">this</span>.warehousePath = <span class="keyword">new</span> <span class="title class_">Path</span>(String.format(<span class="string">&quot;hdfs://%s:%d/user/iceberg/demo&quot;</span>, host, port));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            createTable();</span><br><span class="line">            writeDataToTable();</span><br><span class="line">            readDataFromTable();</span><br><span class="line">            deleteIdEqualsTo(<span class="number">1</span>);</span><br><span class="line">            deleteSpecificRowByPosition(<span class="number">2</span>);</span><br><span class="line">            readDataFromTable();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">if</span> (hadoopCatalog != <span class="literal">null</span>) &#123;</span><br><span class="line">            hadoopCatalog.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">clearPath</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(hdfsConf);</span><br><span class="line">        fileSystem.delete(warehousePath, <span class="literal">true</span>);</span><br><span class="line">        fileSystem.mkdirs(warehousePath);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">createTable</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        clearPath();</span><br><span class="line"></span><br><span class="line">        hadoopCatalog = <span class="keyword">new</span> <span class="title class_">HadoopCatalog</span>(hdfsConf, warehousePath.toString());</span><br><span class="line"></span><br><span class="line">        <span class="type">Schema</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Schema</span>(Types.NestedField.required(<span class="number">1</span>, <span class="string">&quot;id&quot;</span>, Types.IntegerType.get()),</span><br><span class="line">                Types.NestedField.optional(<span class="number">2</span>, <span class="string">&quot;name&quot;</span>, Types.StringType.get()),</span><br><span class="line">                Types.NestedField.optional(<span class="number">3</span>, <span class="string">&quot;age&quot;</span>, Types.IntegerType.get()));</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">namespaceName</span> <span class="operator">=</span> <span class="string">&quot;demo_namespace&quot;</span>;</span><br><span class="line">        <span class="type">Namespace</span> <span class="variable">namespace</span> <span class="operator">=</span> Namespace.of(namespaceName);</span><br><span class="line"></span><br><span class="line">        List&lt;Namespace&gt; namespaces = hadoopCatalog.listNamespaces();</span><br><span class="line">        <span class="keyword">if</span> (!namespaces.contains(namespace)) &#123;</span><br><span class="line">            hadoopCatalog.createNamespace(namespace);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">tablename</span> <span class="operator">=</span> <span class="string">&quot;demo_table&quot;</span>;</span><br><span class="line">        <span class="type">TableIdentifier</span> <span class="variable">tableIdentifier</span> <span class="operator">=</span> TableIdentifier.of(namespaceName, tablename);</span><br><span class="line">        List&lt;TableIdentifier&gt; tableIdentifiers = hadoopCatalog.listTables(namespace);</span><br><span class="line">        <span class="keyword">if</span> (!tableIdentifiers.contains(tableIdentifier)) &#123;</span><br><span class="line">            hadoopCatalog.createTable(tableIdentifier, schema);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        table = hadoopCatalog.loadTable(tableIdentifier);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Record <span class="title function_">buildRecord</span><span class="params">(<span class="type">int</span> id, String name, <span class="type">int</span> age)</span> &#123;</span><br><span class="line">        <span class="type">Record</span> <span class="variable">record</span> <span class="operator">=</span> GenericRecord.create(table.schema());</span><br><span class="line">        record.setField(<span class="string">&quot;id&quot;</span>, id);</span><br><span class="line">        record.setField(<span class="string">&quot;name&quot;</span>, name);</span><br><span class="line">        record.setField(<span class="string">&quot;age&quot;</span>, age);</span><br><span class="line">        records.add(record);</span><br><span class="line">        <span class="keyword">return</span> record;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">writeDataToTable</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">try</span> (<span class="type">FileIO</span> <span class="variable">io</span> <span class="operator">=</span> table.io()) &#123;</span><br><span class="line">            dataFilePath = table.location() + String.format(<span class="string">&quot;/data/%s.parquet&quot;</span>, UUID.randomUUID());</span><br><span class="line">            <span class="type">OutputFile</span> <span class="variable">outputFile</span> <span class="operator">=</span> io.newOutputFile(dataFilePath);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> (FileAppender&lt;Record&gt; writer = Parquet.write(outputFile).schema(table.schema())</span><br><span class="line">                    .createWriterFunc(GenericParquetWriter::buildWriter).build()) &#123;</span><br><span class="line">                writer.add(buildRecord(<span class="number">1</span>, <span class="string">&quot;Alice&quot;</span>, <span class="number">30</span>));</span><br><span class="line">                writer.add(buildRecord(<span class="number">2</span>, <span class="string">&quot;Tom&quot;</span>, <span class="number">18</span>));</span><br><span class="line">                writer.add(buildRecord(<span class="number">3</span>, <span class="string">&quot;Jerry&quot;</span>, <span class="number">22</span>));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="type">DataFile</span> <span class="variable">dataFile</span> <span class="operator">=</span> DataFiles.builder(PartitionSpec.unpartitioned())</span><br><span class="line">                    .withInputFile(outputFile.toInputFile()).withRecordCount(<span class="number">1</span>)</span><br><span class="line">                    .withFormat(FileFormat.PARQUET).build();</span><br><span class="line"></span><br><span class="line">            <span class="type">AppendFiles</span> <span class="variable">append</span> <span class="operator">=</span> table.newAppend();</span><br><span class="line">            append.appendFile(dataFile);</span><br><span class="line">            append.commit();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">deleteSpecificRowByPosition</span><span class="params">(<span class="type">long</span> position)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">try</span> (<span class="type">FileIO</span> <span class="variable">io</span> <span class="operator">=</span> table.io()) &#123;</span><br><span class="line">            <span class="type">OutputFile</span> <span class="variable">outputFile</span> <span class="operator">=</span> io.newOutputFile(</span><br><span class="line">                    table.location() + <span class="string">&quot;/pos-deletes-&quot;</span> + UUID.randomUUID() + <span class="string">&quot;.parquet&quot;</span>);</span><br><span class="line"></span><br><span class="line">            PositionDeleteWriter&lt;Record&gt; writer = Parquet.writeDeletes(outputFile).forTable(table)</span><br><span class="line">                    .rowSchema(table.schema()).createWriterFunc(GenericParquetWriter::buildWriter)</span><br><span class="line">                    .overwrite().withSpec(PartitionSpec.unpartitioned()).buildPositionWriter();</span><br><span class="line"></span><br><span class="line">            PositionDelete&lt;Record&gt; record = PositionDelete.create();</span><br><span class="line">            record = record.set(dataFilePath, position, records.get((<span class="type">int</span>) position));</span><br><span class="line">            <span class="keyword">try</span> (<span class="type">Closeable</span> <span class="variable">ignore</span> <span class="operator">=</span> writer) &#123;</span><br><span class="line">                writer.write(record);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            table.newRowDelta().addDeletes(writer.toDeleteFile()).commit();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        table.refresh();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">deleteIdEqualsTo</span><span class="params">(<span class="type">int</span> id)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        idEqdeleteSchema = <span class="keyword">new</span> <span class="title class_">Schema</span>(Types.NestedField.required(<span class="number">1</span>, <span class="string">&quot;id&quot;</span>, Types.IntegerType.get()));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> (<span class="type">FileIO</span> <span class="variable">io</span> <span class="operator">=</span> table.io()) &#123;</span><br><span class="line">            <span class="type">OutputFile</span> <span class="variable">outputFile</span> <span class="operator">=</span> io.newOutputFile(</span><br><span class="line">                    table.location() + <span class="string">&quot;/equality-deletes-&quot;</span> + UUID.randomUUID() + <span class="string">&quot;.parquet&quot;</span>);</span><br><span class="line"></span><br><span class="line">            EqualityDeleteWriter&lt;Record&gt; writer = Parquet.writeDeletes(outputFile).forTable(table)</span><br><span class="line">                    .rowSchema(idEqdeleteSchema).createWriterFunc(GenericParquetWriter::buildWriter)</span><br><span class="line">                    .overwrite().equalityFieldIds(<span class="number">1</span>).buildEqualityWriter();</span><br><span class="line"></span><br><span class="line">            <span class="type">Record</span> <span class="variable">deleteRecord</span> <span class="operator">=</span> GenericRecord.create(idEqdeleteSchema);</span><br><span class="line">            deleteRecord.setField(<span class="string">&quot;id&quot;</span>, id);</span><br><span class="line">            <span class="keyword">try</span> (<span class="type">Closeable</span> <span class="variable">ignore</span> <span class="operator">=</span> writer) &#123;</span><br><span class="line">                writer.write(deleteRecord);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="type">RowDelta</span> <span class="variable">rowDelta</span> <span class="operator">=</span> table.newRowDelta();</span><br><span class="line">            rowDelta.addDeletes(writer.toDeleteFile()); <span class="comment">// Here, the writer must be at closed state</span></span><br><span class="line">            rowDelta.commit();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        table.refresh();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">readDataFromTable</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Current Snapshot ID: &quot;</span> + table.currentSnapshot().snapshotId());</span><br><span class="line"></span><br><span class="line">        <span class="type">TableScan</span> <span class="variable">scan</span> <span class="operator">=</span> table.newScan();</span><br><span class="line">        <span class="keyword">try</span> (CloseableIterable&lt;FileScanTask&gt; tasks = scan.planFiles()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (FileScanTask task : tasks) &#123;</span><br><span class="line">                List&lt;DeleteFile&gt; deletes = task.deletes();</span><br><span class="line">                Set&lt;Integer&gt; deletedIds = Sets.newHashSet();</span><br><span class="line">                Set&lt;Long&gt; deletedPos = Sets.newHashSet();</span><br><span class="line">                <span class="keyword">for</span> (DeleteFile delete : deletes) &#123;</span><br><span class="line">                    <span class="keyword">switch</span> (delete.content()) &#123;</span><br><span class="line">                        <span class="keyword">case</span> EQUALITY_DELETES:</span><br><span class="line">                            <span class="keyword">try</span> (<span class="type">FileIO</span> <span class="variable">io</span> <span class="operator">=</span> table.io()) &#123;</span><br><span class="line">                                <span class="type">InputFile</span> <span class="variable">inputFile</span> <span class="operator">=</span> io.newInputFile(delete.path().toString());</span><br><span class="line">                                <span class="keyword">try</span> (CloseableIterable&lt;Record&gt; records = Parquet.read(inputFile)</span><br><span class="line">                                        .project(idEqdeleteSchema)</span><br><span class="line">                                        .createReaderFunc(messageType -&gt; GenericParquetReaders</span><br><span class="line">                                                .buildReader(idEqdeleteSchema, messageType))</span><br><span class="line">                                        .build()) &#123;</span><br><span class="line"></span><br><span class="line">                                    <span class="keyword">for</span> (Record record : records) &#123;</span><br><span class="line">                                        System.out.println(<span class="string">&quot;Equality delete record: &quot;</span> + record);</span><br><span class="line">                                        deletedIds.add((<span class="type">int</span>) record.getField(<span class="string">&quot;id&quot;</span>));</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">break</span>;</span><br><span class="line">                        <span class="keyword">case</span> POSITION_DELETES:</span><br><span class="line">                            <span class="keyword">try</span> (<span class="type">FileIO</span> <span class="variable">io</span> <span class="operator">=</span> table.io()) &#123;</span><br><span class="line">                                <span class="type">InputFile</span> <span class="variable">inputFile</span> <span class="operator">=</span> io.newInputFile(delete.path().toString());</span><br><span class="line">                                <span class="keyword">try</span> (CloseableIterable&lt;Record&gt; records = Parquet.read(inputFile)</span><br><span class="line">                                        .project(POSITIONAL_DELETE_SCHEMA)</span><br><span class="line">                                        .createReaderFunc(messageType -&gt; GenericParquetReaders</span><br><span class="line">                                                .buildReader(POSITIONAL_DELETE_SCHEMA, messageType))</span><br><span class="line">                                        .build()) &#123;</span><br><span class="line"></span><br><span class="line">                                    <span class="keyword">for</span> (Record record : records) &#123;</span><br><span class="line">                                        System.out.println(<span class="string">&quot;Position delete record: &quot;</span> + record);</span><br><span class="line">                                        deletedPos.add((<span class="type">long</span>) record.getField(<span class="string">&quot;pos&quot;</span>));</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">try</span> (<span class="type">FileIO</span> <span class="variable">io</span> <span class="operator">=</span> table.io()) &#123;</span><br><span class="line">                    <span class="type">InputFile</span> <span class="variable">inputFile</span> <span class="operator">=</span> io.newInputFile(task.file().path().toString());</span><br><span class="line">                    <span class="keyword">try</span> (CloseableIterable&lt;Record&gt; records =</span><br><span class="line">                            Parquet.read(inputFile).project(table.schema())</span><br><span class="line">                                    .createReaderFunc(messageType -&gt; GenericParquetReaders</span><br><span class="line">                                            .buildReader(table.schema(), messageType))</span><br><span class="line">                                    .build()) &#123;</span><br><span class="line"></span><br><span class="line">                        <span class="type">long</span> <span class="variable">pos</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">                        <span class="keyword">for</span> (Record record : records) &#123;</span><br><span class="line">                            pos++;</span><br><span class="line">                            <span class="keyword">if</span> (!deletedIds.contains((<span class="type">int</span>) record.getField(<span class="string">&quot;id&quot;</span>))</span><br><span class="line">                                    &amp;&amp; !deletedPos.contains(pos)) &#123;</span><br><span class="line">                                System.out.println(record);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">IceBergDemo</span> <span class="variable">iceBergDemo</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IceBergDemo</span>(<span class="string">&quot;192.168.64.2&quot;</span>, <span class="number">9000</span>);</span><br><span class="line">        iceBergDemo.run();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="5-tips"><a class="markdownIt-Anchor" href="#5-tips"></a> 5 Tips</h1>
<h2 id="51-reserved-field-ids"><a class="markdownIt-Anchor" href="#51-reserved-field-ids"></a> 5.1 Reserved Field Ids</h2>
<p>Refer to <a target="_blank" rel="noopener" href="https://github.com/apache/iceberg/blob/main/format/spec.md">Reserved Field IDs</a> for details.</p>
<h1 id="6-reference"><a class="markdownIt-Anchor" href="#6-reference"></a> 6 Reference</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://iceberg.apache.org/docs/nightly/">Iceberg Docs</a></li>
<li><a target="_blank" rel="noopener" href="https://iceberg.apache.org/spec/">Iceberg Spec</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/wP9q7NACYEyY-TdrSceq4A">优化数据查询性能：StarRocks 与 Apache Iceberg 的强强联合</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/pIXKXKNBLG5EPkAkiowBLQ">StarRocks Lakehouse 快速入门——Apache Iceberg</a></li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%8E%9F%E5%88%9B/" rel="tag"># 原创</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/06/18/Linux-IO/" rel="prev" title="Linux-IO">
      <i class="fa fa-chevron-left"></i> Linux-IO
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/03/23/Rust-Basics/" rel="next" title="Rust-Basics">
      Rust-Basics <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
      <div class="tabs tabs-comment">
        <ul class="nav-tabs">
            <li class="tab"><a href="#comment-livere">livere</a></li>
            <li class="tab"><a href="#comment-valine">valine</a></li>
        </ul>
        <div class="tab-content">
            <div class="tab-pane livere" id="comment-livere">
              
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC8zMzY0My8xMDE5OA=="></div>
  </div>
  
            </div>
            <div class="tab-pane valine" id="comment-valine">
              <div class="comments" id="valine-comments"></div>
            </div>
        </div>
      </div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-killing-feature"><span class="nav-text"> 1 Killing Feature</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-spark-iceberg"><span class="nav-text"> 2 Spark &amp; Iceberg</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#21-step1-create-a-shared-network"><span class="nav-text"> 2.1 Step1: Create a shared network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#22-step2-start-hadoop"><span class="nav-text"> 2.2 Step2: Start Hadoop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#23-step3-start-spark"><span class="nav-text"> 2.3 Step3: Start Spark</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-trino-iceberg"><span class="nav-text"> 3 Trino &amp; Iceberg</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#31-step1-step2"><span class="nav-text"> 3.1 Step1 &amp; Step2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#32-step3-start-hive"><span class="nav-text"> 3.2 Step3: Start Hive</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#33-step4-start-trino"><span class="nav-text"> 3.3 Step4: Start Trino</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-api-demo"><span class="nav-text"> 4 API-Demo</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-tips"><span class="nav-text"> 5 Tips</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#51-reserved-field-ids"><span class="nav-text"> 5.1 Reserved Field Ids</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-reference"><span class="nav-text"> 6 Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Liuyehcf"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Liuyehcf</p>
  <div class="site-description" itemprop="description">大音希声，大象无形</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">285</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">99</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liuyehcf</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qhEhLuMeMOy1zgcBhkqUS6P8-gzGzoHsz',
      appKey     : 'uhkruDLNLNdL5rQjRBY2X9Ke',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
